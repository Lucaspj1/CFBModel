{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23207550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cfbd\n",
      "  Using cached cfbd-5.13.2-py3-none-any.whl.metadata (737 bytes)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.25.3 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from cfbd) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from cfbd) (2.9.0.post0)\n",
      "Collecting pydantic<2,>=1.10.5 (from cfbd)\n",
      "  Using cached pydantic-1.10.24-cp313-cp313-macosx_11_0_arm64.whl.metadata (154 kB)\n",
      "Collecting aenum (from cfbd)\n",
      "  Using cached aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from pydantic<2,>=1.10.5->cfbd) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from python-dateutil->cfbd) (1.17.0)\n",
      "Using cached cfbd-5.13.2-py3-none-any.whl (245 kB)\n",
      "Using cached pydantic-1.10.24-cp313-cp313-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Using cached aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Installing collected packages: aenum, pydantic, cfbd\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [cfbd][32m2/3\u001b[0m [cfbd]tic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aenum-3.1.16 cfbd-5.13.2 pydantic-1.10.24\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cfbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "14a39cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import cfbd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41b98a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CompleteCFBDataPipeline:\n",
    "    \"\"\"\n",
    "    Complete pipeline to download ALL CFB data and create one comprehensive dataset.\n",
    "    One row per team per game with all available statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"Initialize with API key.\"\"\"\n",
    "        if not api_key or api_key == \"YOUR_API_KEY_HERE\":\n",
    "            raise ValueError(\n",
    "                \"Invalid API key! Please set your actual CFBD API key.\\n\"\n",
    "                \"Get your key at: https://collegefootballdata.com/key\"\n",
    "            )\n",
    "        \n",
    "        self.api_key = api_key\n",
    "        self.api_call_count = 0\n",
    "        \n",
    "        # Configure API\n",
    "        configuration = cfbd.Configuration()\n",
    "        configuration.access_token = api_key\n",
    "        self.api_client = cfbd.ApiClient(configuration)\n",
    "        \n",
    "        # Initialize API instances\n",
    "        self.games_api = cfbd.GamesApi(self.api_client)\n",
    "        self.stats_api = cfbd.StatsApi(self.api_client)\n",
    "        self.teams_api = cfbd.TeamsApi(self.api_client)\n",
    "        self.ratings_api = cfbd.RatingsApi(self.api_client)\n",
    "        self.recruiting_api = cfbd.RecruitingApi(self.api_client)\n",
    "        self.betting_api = cfbd.BettingApi(self.api_client)\n",
    "        self.metrics_api = cfbd.MetricsApi(self.api_client)\n",
    "        self.plays_api = cfbd.PlaysApi(self.api_client)\n",
    "        \n",
    "        print(\"✓ CFB Data Pipeline initialized\")\n",
    "        print(\"\\nTesting API connection...\")\n",
    "        self._test_api_connection()\n",
    "    \n",
    "    def _test_api_connection(self):\n",
    "        \"\"\"Test that API key is valid.\"\"\"\n",
    "        try:\n",
    "            # Simple test call\n",
    "            test = self.teams_api.get_fbs_teams(year=2024)\n",
    "            print(f\"✓ API connection successful! Found {len(test)} FBS teams for 2024\")\n",
    "        except Exception as e:\n",
    "            if \"401\" in str(e) or \"Unauthorized\" in str(e):\n",
    "                raise ValueError(\n",
    "                    \"\\n\" + \"=\" * 70 + \"\\n\"\n",
    "                    \"ERROR: API Key is Invalid or Unauthorized!\\n\"\n",
    "                    \"=\" * 70 + \"\\n\"\n",
    "                    \"Please check:\\n\"\n",
    "                    \"1. Your API key is correct\\n\"\n",
    "                    \"2. You have an active subscription at collegefootballdata.com\\n\"\n",
    "                    \"3. Your API key is properly copied (no extra spaces)\\n\\n\"\n",
    "                    \"Get your API key at: https://collegefootballdata.com/key\\n\"\n",
    "                    \"=\" * 70\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"API connection test failed: {str(e)}\")\n",
    "    \n",
    "    def track_call(self, name):\n",
    "        \"\"\"Track API calls.\"\"\"\n",
    "        self.api_call_count += 1\n",
    "        print(f\"  API Call #{self.api_call_count}: {name}\")\n",
    "    \n",
    "    def get_all_data(self, years=[2024], season_type='regular'):\n",
    "        \"\"\"\n",
    "        Download ALL data and create one comprehensive dataset.\n",
    "        \n",
    "        Args:\n",
    "            years: List of years to download (e.g., [2024] or list(range(2015, 2025)))\n",
    "            season_type: 'regular', 'postseason', or 'both'\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with one row per team per game with all stats\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"COMPLETE CFB DATA DOWNLOAD\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"\\nYears: {years}\")\n",
    "        print(f\"Season type: {season_type}\")\n",
    "        print(f\"\\nThis will download:\")\n",
    "        print(\"  ✓ Game results & details\")\n",
    "        print(\"  ✓ Advanced game statistics (EPA, explosiveness, etc.)\")\n",
    "        print(\"  ✓ Play-by-play aggregated stats (sacks, turnovers, etc.)\")\n",
    "        print(\"  ✓ SP+ ratings\")\n",
    "        print(\"  ✓ FPI ratings\")\n",
    "        print(\"  ✓ Team talent composite\")\n",
    "        print(\"  ✓ Recruiting rankings\")\n",
    "        print(\"  ✓ Betting lines\")\n",
    "        print(\"  ✓ Pregame win probabilities\")\n",
    "        \n",
    "        season_types = ['regular', 'postseason'] if season_type == 'both' else [season_type]\n",
    "        \n",
    "        # Download all components\n",
    "        games_df = self._download_games(years, season_types)\n",
    "        advanced_stats_df = self._download_advanced_stats(years, season_types)\n",
    "        pbp_stats_df = self._download_play_stats(years, season_types)\n",
    "        drive_stats_df = self._download_drive_stats(years, season_types)\n",
    "        adjusted_metrics_df = self._download_adjusted_metrics(years)\n",
    "        sp_ratings_df = self._download_sp_ratings(years)\n",
    "        fpi_ratings_df = self._download_fpi_ratings(years)\n",
    "        talent_df = self._download_talent(years)\n",
    "        recruiting_df = self._download_recruiting(years)\n",
    "        betting_df = self._download_betting(years, season_types)\n",
    "        win_prob_df = self._download_win_probs(years, season_types)\n",
    "        \n",
    "        # Merge everything\n",
    "        final_df = self._merge_all_data(\n",
    "            games_df, advanced_stats_df, pbp_stats_df, drive_stats_df, \n",
    "            adjusted_metrics_df, sp_ratings_df, fpi_ratings_df, talent_df, \n",
    "            recruiting_df, betting_df, win_prob_df\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(\"DOWNLOAD COMPLETE!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"✓ Total API calls used: {self.api_call_count}\")\n",
    "        print(f\"✓ Final dataset shape: {final_df.shape}\")\n",
    "        print(f\"✓ Total games: {len(final_df) / 2:.0f}\")\n",
    "        print(f\"✓ Total features: {len(final_df.columns)}\")\n",
    "        \n",
    "        return final_df\n",
    "    \n",
    "    def _download_games(self, years, season_types):\n",
    "        \"\"\"Download basic game data.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"1. DOWNLOADING GAME RESULTS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_games = []\n",
    "        \n",
    "        for year in years:\n",
    "            for stype in season_types:\n",
    "                self.track_call(f\"get_games({year}, {stype})\")\n",
    "                games = self.games_api.get_games(year=year, season_type=stype)\n",
    "                \n",
    "                for g in games:\n",
    "                    all_games.append({\n",
    "                        'game_id': g.id,\n",
    "                        'season': g.season,\n",
    "                        'week': g.week,\n",
    "                        'season_type': g.season_type,\n",
    "                        'start_date': g.start_date,\n",
    "                        'neutral_site': g.neutral_site,\n",
    "                        'conference_game': g.conference_game,\n",
    "                        'attendance': g.attendance,\n",
    "                        'venue_id': g.venue_id,\n",
    "                        'venue': g.venue,\n",
    "                        'home_id': g.home_id,\n",
    "                        'home_team': g.home_team,\n",
    "                        'home_conference': g.home_conference,\n",
    "                        'home_points': g.home_points,\n",
    "                        'away_id': g.away_id,\n",
    "                        'away_team': g.away_team,\n",
    "                        'away_conference': g.away_conference,\n",
    "                        'away_points': g.away_points,\n",
    "                        'excitement_index': g.excitement_index\n",
    "                    })\n",
    "                \n",
    "                print(f\"  {year} {stype}: {len(games)} games\")\n",
    "                time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_games)\n",
    "        print(f\"\\n✓ Downloaded {len(df)} games\")\n",
    "        return df\n",
    "    \n",
    "    def _download_advanced_stats(self, years, season_types):\n",
    "        \"\"\"Download advanced game statistics.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"2. DOWNLOADING ADVANCED GAME STATS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_stats = []\n",
    "        \n",
    "        for year in years:\n",
    "            for stype in season_types:\n",
    "                self.track_call(f\"get_advanced_game_stats({year}, {stype})\")\n",
    "                stats = self.stats_api.get_advanced_game_stats(year=year, season_type=stype)\n",
    "                \n",
    "                for s in stats:\n",
    "                    data = {\n",
    "                        'game_id': s.game_id,\n",
    "                        'team': s.team,\n",
    "                        'opponent': s.opponent\n",
    "                    }\n",
    "                    \n",
    "                    # Flatten offense\n",
    "                    if s.offense:\n",
    "                        data['off_plays'] = s.offense.plays\n",
    "                        data['off_drives'] = s.offense.drives\n",
    "                        data['off_ppa'] = s.offense.ppa\n",
    "                        data['off_total_ppa'] = s.offense.total_ppa\n",
    "                        data['off_success_rate'] = s.offense.success_rate\n",
    "                        data['off_explosiveness'] = s.offense.explosiveness\n",
    "                        data['off_power_success'] = s.offense.power_success\n",
    "                        data['off_stuff_rate'] = s.offense.stuff_rate\n",
    "                        data['off_line_yards'] = s.offense.line_yards\n",
    "                        data['off_line_yards_total'] = s.offense.line_yards_total\n",
    "                        data['off_second_level_yards'] = s.offense.second_level_yards\n",
    "                        data['off_second_level_yards_total'] = s.offense.second_level_yards_total\n",
    "                        data['off_open_field_yards'] = s.offense.open_field_yards\n",
    "                        data['off_open_field_yards_total'] = s.offense.open_field_yards_total\n",
    "                        \n",
    "                        # Passing\n",
    "                        if s.offense.passing_plays:\n",
    "                            data['off_pass_ppa'] = s.offense.passing_plays.ppa\n",
    "                            data['off_pass_total_ppa'] = s.offense.passing_plays.total_ppa\n",
    "                            data['off_pass_success_rate'] = s.offense.passing_plays.success_rate\n",
    "                            data['off_pass_explosiveness'] = s.offense.passing_plays.explosiveness\n",
    "                        \n",
    "                        # Rushing\n",
    "                        if s.offense.rushing_plays:\n",
    "                            data['off_rush_ppa'] = s.offense.rushing_plays.ppa\n",
    "                            data['off_rush_total_ppa'] = s.offense.rushing_plays.total_ppa\n",
    "                            data['off_rush_success_rate'] = s.offense.rushing_plays.success_rate\n",
    "                            data['off_rush_explosiveness'] = s.offense.rushing_plays.explosiveness\n",
    "                        \n",
    "                        # Standard downs\n",
    "                        if s.offense.standard_downs:\n",
    "                            data['off_standard_downs_ppa'] = s.offense.standard_downs.ppa\n",
    "                            data['off_standard_downs_success_rate'] = s.offense.standard_downs.success_rate\n",
    "                            data['off_standard_downs_explosiveness'] = s.offense.standard_downs.explosiveness\n",
    "                        \n",
    "                        # Passing downs\n",
    "                        if s.offense.passing_downs:\n",
    "                            data['off_passing_downs_ppa'] = s.offense.passing_downs.ppa\n",
    "                            data['off_passing_downs_success_rate'] = s.offense.passing_downs.success_rate\n",
    "                            data['off_passing_downs_explosiveness'] = s.offense.passing_downs.explosiveness\n",
    "                    \n",
    "                    # Flatten defense\n",
    "                    if s.defense:\n",
    "                        data['def_plays'] = s.defense.plays\n",
    "                        data['def_drives'] = s.defense.drives\n",
    "                        data['def_ppa'] = s.defense.ppa\n",
    "                        data['def_total_ppa'] = s.defense.total_ppa\n",
    "                        data['def_success_rate'] = s.defense.success_rate\n",
    "                        data['def_explosiveness'] = s.defense.explosiveness\n",
    "                        data['def_power_success'] = s.defense.power_success\n",
    "                        data['def_stuff_rate'] = s.defense.stuff_rate\n",
    "                        data['def_line_yards'] = s.defense.line_yards\n",
    "                        data['def_line_yards_total'] = s.defense.line_yards_total\n",
    "                        data['def_second_level_yards'] = s.defense.second_level_yards\n",
    "                        data['def_second_level_yards_total'] = s.defense.second_level_yards_total\n",
    "                        data['def_open_field_yards'] = s.defense.open_field_yards\n",
    "                        data['def_open_field_yards_total'] = s.defense.open_field_yards_total\n",
    "                        \n",
    "                        if s.defense.passing_plays:\n",
    "                            data['def_pass_ppa'] = s.defense.passing_plays.ppa\n",
    "                            data['def_pass_total_ppa'] = s.defense.passing_plays.total_ppa\n",
    "                            data['def_pass_success_rate'] = s.defense.passing_plays.success_rate\n",
    "                            data['def_pass_explosiveness'] = s.defense.passing_plays.explosiveness\n",
    "                        \n",
    "                        if s.defense.rushing_plays:\n",
    "                            data['def_rush_ppa'] = s.defense.rushing_plays.ppa\n",
    "                            data['def_rush_total_ppa'] = s.defense.rushing_plays.total_ppa\n",
    "                            data['def_rush_success_rate'] = s.defense.rushing_plays.success_rate\n",
    "                            data['def_rush_explosiveness'] = s.defense.rushing_plays.explosiveness\n",
    "                        \n",
    "                        if s.defense.standard_downs:\n",
    "                            data['def_standard_downs_ppa'] = s.defense.standard_downs.ppa\n",
    "                            data['def_standard_downs_success_rate'] = s.defense.standard_downs.success_rate\n",
    "                            data['def_standard_downs_explosiveness'] = s.defense.standard_downs.explosiveness\n",
    "                        \n",
    "                        if s.defense.passing_downs:\n",
    "                            data['def_passing_downs_ppa'] = s.defense.passing_downs.ppa\n",
    "                            data['def_passing_downs_success_rate'] = s.defense.passing_downs.success_rate\n",
    "                            data['def_passing_downs_explosiveness'] = s.defense.passing_downs.explosiveness\n",
    "                    \n",
    "                    all_stats.append(data)\n",
    "                \n",
    "                print(f\"  {year} {stype}: {len(stats)} team-games\")\n",
    "                time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_stats)\n",
    "        print(f\"\\n✓ Downloaded {len(df)} advanced stat records\")\n",
    "        return df\n",
    "    \n",
    "    def _download_play_stats(self, years, season_types):\n",
    "        \"\"\"Download individual GAME team stats (passing yards, rushing yards, sacks, turnovers per game).\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"3. DOWNLOADING GAME-LEVEL TEAM STATS (Passing, Rushing, Sacks, Turnovers)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_stats = []\n",
    "        \n",
    "        for year in years:\n",
    "            for stype in season_types:\n",
    "                # Need to loop through weeks (1-16 for regular season)\n",
    "                max_week = 16 if stype == 'regular' else 5\n",
    "                \n",
    "                for week in range(1, max_week + 1):\n",
    "                    self.track_call(f\"get_game_team_stats({year}, week={week}, {stype})\")\n",
    "                    \n",
    "                    try:\n",
    "                        game_stats = self.games_api.get_game_team_stats(\n",
    "                            year=year,\n",
    "                            week=week,\n",
    "                            season_type=stype\n",
    "                        )\n",
    "                        \n",
    "                        # Each game_stat is a GameTeamStats object\n",
    "                        for game in game_stats:\n",
    "                            # game.teams is a list of GameTeamStatsTeam objects (one per team)\n",
    "                            if game.teams:\n",
    "                                for team_data in game.teams:\n",
    "                                    stat_dict = {\n",
    "                                        'game_id': game.id,\n",
    "                                        'team': team_data.team,\n",
    "                                        'conference': team_data.conference,\n",
    "                                        'home_away': team_data.home_away,\n",
    "                                        'points': team_data.points\n",
    "                                    }\n",
    "                                    \n",
    "                                    # Extract all stats from the stats list\n",
    "                                    if team_data.stats:\n",
    "                                        for stat in team_data.stats:\n",
    "                                            # stat.category is like \"totalYards\", stat.stat is the value\n",
    "                                            stat_dict[f'game_{stat.category}'] = stat.stat\n",
    "                                    \n",
    "                                    all_stats.append(stat_dict)\n",
    "                        \n",
    "                        if len(game_stats) > 0:\n",
    "                            print(f\"  {year} {stype} Week {week}: {len(game_stats)} games ({len(game_stats)*2} team-games)\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        if \"404\" not in str(e):  # Don't print for weeks that don't exist\n",
    "                            print(f\"  {year} {stype} Week {week}: Error - {str(e)}\")\n",
    "                    \n",
    "                    time.sleep(0.1)\n",
    "        \n",
    "        if len(all_stats) == 0:\n",
    "            print(f\"\\n⚠ No game team stats available\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(all_stats)\n",
    "        \n",
    "        # Drop unnecessary columns for merging\n",
    "        df = df.drop(columns=['conference', 'home_away', 'points'], errors='ignore')\n",
    "        \n",
    "        # Show what stats are available\n",
    "        stat_cols = [c for c in df.columns if c.startswith('game_')]\n",
    "        print(f\"\\n✓ Downloaded individual game team stats\")\n",
    "        print(f\"  Team-games: {len(df)}\")\n",
    "        print(f\"  Stat categories: {len(stat_cols)}\")\n",
    "        print(f\"\\n  Sample stats available:\")\n",
    "        for col in sorted(stat_cols)[:25]:\n",
    "            print(f\"    • {col}\")\n",
    "        if len(stat_cols) > 25:\n",
    "            print(f\"    ... and {len(stat_cols) - 25} more\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _download_drive_stats(self, years, season_types):\n",
    "        \"\"\"Download drive-level statistics for field position and drive outcomes.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"4. DOWNLOADING DRIVE-LEVEL DATA (Field Position, Drive Results)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        drives_api = cfbd.DrivesApi(self.api_client)\n",
    "        all_drives = []\n",
    "        \n",
    "        for year in years:\n",
    "            for stype in season_types:\n",
    "                self.track_call(f\"get_drives({year}, {stype})\")\n",
    "                \n",
    "                try:\n",
    "                    drives = drives_api.get_drives(\n",
    "                        year=year,\n",
    "                        season_type=stype\n",
    "                    )\n",
    "                    \n",
    "                    for drive in drives:\n",
    "                        all_drives.append({\n",
    "                            'game_id': int(drive.game_id) if hasattr(drive, 'game_id') and drive.game_id else None,  # Use game_id, not id\n",
    "                            'team': drive.offense,\n",
    "                            'opponent': drive.defense,\n",
    "                            'drive_number': drive.drive_number,\n",
    "                            'start_period': drive.start_period,\n",
    "                            'start_yardline': drive.start_yardline,\n",
    "                            'start_yards_to_goal': drive.start_yards_to_goal,\n",
    "                            'end_period': drive.end_period,\n",
    "                            'end_yardline': drive.end_yardline,\n",
    "                            'end_yards_to_goal': drive.end_yards_to_goal,\n",
    "                            'plays': drive.plays,\n",
    "                            'yards': drive.yards,\n",
    "                            'drive_result': drive.drive_result,\n",
    "                            'elapsed_time': drive.elapsed\n",
    "                        })\n",
    "                    \n",
    "                    print(f\"  {year} {stype}: {len(drives)} drives\")\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  {year} {stype}: Error - {str(e)}\")\n",
    "        \n",
    "        if len(all_drives) == 0:\n",
    "            print(f\"\\n⚠ No drive data available\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(all_drives)\n",
    "        \n",
    "        # Ensure game_id is integer type\n",
    "        df['game_id'] = pd.to_numeric(df['game_id'], errors='coerce').astype('Int64')\n",
    "        \n",
    "        # Remove rows with null game_id\n",
    "        df = df[df['game_id'].notna()]\n",
    "        \n",
    "        print(f\"\\nTotal drives downloaded: {len(df)}\")\n",
    "        print(f\"Unique games: {df['game_id'].nunique()}\")\n",
    "        print(f\"Unique teams: {df['team'].nunique()}\")\n",
    "        \n",
    "        # Aggregate drive data by game and team\n",
    "        print(f\"Aggregating drive data by game and team...\")\n",
    "        \n",
    "        # Calculate drive success metrics first (before aggregation)\n",
    "        df['reached_redzone'] = df['end_yards_to_goal'] <= 20\n",
    "        df['reached_scoring_zone'] = df['end_yards_to_goal'] <= 40\n",
    "        df['reached_plus_territory'] = df['end_yards_to_goal'] <= 50\n",
    "        df['successful_drive'] = df['drive_result'].isin(['TD', 'FG', 'TOUCHDOWN', 'FIELD GOAL'])\n",
    "        df['scored_td'] = df['drive_result'].isin(['TD', 'TOUCHDOWN'])\n",
    "        \n",
    "        # Now aggregate by game_id and team\n",
    "        drive_agg = df.groupby(['game_id', 'team'], as_index=False).agg({\n",
    "            # Field position\n",
    "            'start_yards_to_goal': 'mean',\n",
    "            \n",
    "            # Drive outcomes  \n",
    "            'scored_td': 'sum',\n",
    "            'plays': 'mean',\n",
    "            'yards': 'mean',\n",
    "            'drive_number': 'count',\n",
    "            \n",
    "            # Success metrics\n",
    "            'reached_redzone': 'sum',\n",
    "            'reached_scoring_zone': 'sum',\n",
    "            'reached_plus_territory': 'sum',\n",
    "            'successful_drive': 'sum'\n",
    "        })\n",
    "        \n",
    "        # Rename columns\n",
    "        drive_agg.columns = [\n",
    "            'game_id', 'team',\n",
    "            'avg_start_field_position',\n",
    "            'touchdowns_scored',\n",
    "            'avg_plays_per_drive',\n",
    "            'avg_yards_per_drive',\n",
    "            'total_drives',\n",
    "            'drives_to_redzone',\n",
    "            'drives_to_scoring_zone',\n",
    "            'drives_to_plus_territory',\n",
    "            'successful_drives'\n",
    "        ]\n",
    "        \n",
    "        # Calculate rates\n",
    "        drive_agg['scoring_drive_rate'] = drive_agg['touchdowns_scored'] / drive_agg['total_drives']\n",
    "        drive_agg['redzone_rate'] = drive_agg['drives_to_redzone'] / drive_agg['total_drives']\n",
    "        drive_agg['scoring_zone_rate'] = drive_agg['drives_to_scoring_zone'] / drive_agg['total_drives']\n",
    "        drive_agg['plus_territory_rate'] = drive_agg['drives_to_plus_territory'] / drive_agg['total_drives']\n",
    "        drive_agg['drive_success_rate'] = drive_agg['successful_drives'] / drive_agg['total_drives']\n",
    "        \n",
    "        # Ensure game_id is integer type in final output\n",
    "        drive_agg['game_id'] = drive_agg['game_id'].astype('Int64')\n",
    "        \n",
    "        print(f\"\\n✓ Aggregated drive data\")\n",
    "        print(f\"  Team-games: {len(drive_agg)}\")\n",
    "        print(f\"  Games covered: {drive_agg['game_id'].nunique()}\")\n",
    "        print(f\"  Teams covered: {drive_agg['team'].nunique()}\")\n",
    "        print(f\"  Metrics: {len(drive_agg.columns) - 2}\")\n",
    "        print(f\"\\n  Sample game_ids: {drive_agg['game_id'].head(3).tolist()}\")\n",
    "        print(f\"  Sample teams: {drive_agg['team'].head(3).tolist()}\")\n",
    "        \n",
    "        return drive_agg\n",
    "    \n",
    "    def _download_adjusted_metrics(self, years):\n",
    "        \"\"\"Download opponent-adjusted team season metrics (success rates).\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"5. DOWNLOADING ADJUSTED METRICS (Opponent-Adjusted Success Rates)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_metrics = []\n",
    "        \n",
    "        for year in years:\n",
    "            self.track_call(f\"get_adjusted_team_season_stats({year})\")\n",
    "            \n",
    "            try:\n",
    "                # Use the adjusted_metrics API endpoint\n",
    "                metrics = self.stats_api.get_advanced_team_season_stats(\n",
    "                    year=year,\n",
    "                    exclude_garbage_time=True  # Exclude garbage time for better metrics\n",
    "                )\n",
    "                \n",
    "                for m in metrics:\n",
    "                    data = {\n",
    "                        'year': m.season,\n",
    "                        'team': m.team,\n",
    "                        'conference': m.conference\n",
    "                    }\n",
    "                    \n",
    "                    # Extract offense metrics\n",
    "                    if m.offense:\n",
    "                        data['adj_off_success_rate'] = m.offense.success_rate if hasattr(m.offense, 'success_rate') else None\n",
    "                        data['adj_off_explosiveness'] = m.offense.explosiveness if hasattr(m.offense, 'explosiveness') else None\n",
    "                        data['adj_off_ppa'] = m.offense.ppa if hasattr(m.offense, 'ppa') else None\n",
    "                    \n",
    "                    # Extract defense metrics  \n",
    "                    if m.defense:\n",
    "                        data['adj_def_success_rate'] = m.defense.success_rate if hasattr(m.defense, 'success_rate') else None\n",
    "                        data['adj_def_explosiveness'] = m.defense.explosiveness if hasattr(m.defense, 'explosiveness') else None\n",
    "                        data['adj_def_ppa'] = m.defense.ppa if hasattr(m.defense, 'ppa') else None\n",
    "                    \n",
    "                    all_metrics.append(data)\n",
    "                \n",
    "                print(f\"  {year}: {len(metrics)} teams\")\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  {year}: Error - {str(e)}\")\n",
    "        \n",
    "        if len(all_metrics) == 0:\n",
    "            print(f\"\\n⚠ No adjusted metrics available\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(all_metrics)\n",
    "        print(f\"\\n✓ Downloaded adjusted metrics for {len(df)} teams\")\n",
    "        return df\n",
    "    \n",
    "    def _download_sp_ratings(self, years):\n",
    "        \"\"\"Download SP+ ratings.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"4. DOWNLOADING SP+ RATINGS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_ratings = []\n",
    "        \n",
    "        for year in years:\n",
    "            self.track_call(f\"get_sp({year})\")\n",
    "            ratings = self.ratings_api.get_sp(year=year)\n",
    "            \n",
    "            for r in ratings:\n",
    "                data = {\n",
    "                    'year': r.year,\n",
    "                    'team': r.team,\n",
    "                    'sp_rating': r.rating,\n",
    "                    'sp_ranking': r.ranking\n",
    "                }\n",
    "                \n",
    "                if r.offense:\n",
    "                    data['sp_offense'] = r.offense.rating\n",
    "                    data['sp_offense_ranking'] = r.offense.ranking\n",
    "                \n",
    "                if r.defense:\n",
    "                    data['sp_defense'] = r.defense.rating\n",
    "                    data['sp_defense_ranking'] = r.defense.ranking\n",
    "                \n",
    "                if r.special_teams:\n",
    "                    data['sp_special_teams'] = r.special_teams.rating\n",
    "                \n",
    "                all_ratings.append(data)\n",
    "            \n",
    "            print(f\"  {year}: {len(ratings)} teams\")\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_ratings)\n",
    "        print(f\"\\n✓ Downloaded {len(df)} SP+ ratings\")\n",
    "        return df\n",
    "    \n",
    "    def _download_fpi_ratings(self, years):\n",
    "        \"\"\"Download FPI ratings.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"5. DOWNLOADING FPI RATINGS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_ratings = []\n",
    "        \n",
    "        for year in years:\n",
    "            self.track_call(f\"get_fpi({year})\")\n",
    "            \n",
    "            try:\n",
    "                ratings = self.ratings_api.get_fpi(year=year)\n",
    "                \n",
    "                for r in ratings:\n",
    "                    data = {\n",
    "                        'year': r.year,\n",
    "                        'team': r.team,\n",
    "                        'fpi': r.fpi\n",
    "                    }\n",
    "                    \n",
    "                    if r.efficiencies:\n",
    "                        data['fpi_offense'] = r.efficiencies.offense\n",
    "                        data['fpi_defense'] = r.efficiencies.defense\n",
    "                        data['fpi_special_teams'] = r.efficiencies.special_teams\n",
    "                    \n",
    "                    all_ratings.append(data)\n",
    "                \n",
    "                print(f\"  {year}: {len(ratings)} teams\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {year}: Not available\")\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_ratings)\n",
    "        if len(df) > 0:\n",
    "            print(f\"\\n✓ Downloaded {len(df)} FPI ratings\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ No FPI ratings available\")\n",
    "        return df\n",
    "    \n",
    "    def _download_talent(self, years):\n",
    "        \"\"\"Download team talent composite.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"6. DOWNLOADING TEAM TALENT RATINGS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_talent = []\n",
    "        \n",
    "        for year in years:\n",
    "            self.track_call(f\"get_talent({year})\")\n",
    "            \n",
    "            try:\n",
    "                talent = self.teams_api.get_talent(year=year)\n",
    "                \n",
    "                for t in talent:\n",
    "                    all_talent.append({\n",
    "                        'year': t.year,\n",
    "                        'team': t.school,\n",
    "                        'talent': t.talent\n",
    "                    })\n",
    "                \n",
    "                print(f\"  {year}: {len(talent)} teams\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {year}: Not available\")\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_talent)\n",
    "        if len(df) > 0:\n",
    "            print(f\"\\n✓ Downloaded {len(df)} talent ratings\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ No talent ratings available\")\n",
    "        return df\n",
    "    \n",
    "    def _download_recruiting(self, years):\n",
    "        \"\"\"Download recruiting rankings.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"7. DOWNLOADING RECRUITING RANKINGS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_recruiting = []\n",
    "        \n",
    "        for year in years:\n",
    "            self.track_call(f\"get_team_recruiting_rankings({year})\")\n",
    "            rankings = self.recruiting_api.get_team_recruiting_rankings(year=year)\n",
    "            \n",
    "            for r in rankings:\n",
    "                all_recruiting.append({\n",
    "                    'year': r.year,\n",
    "                    'team': r.team,\n",
    "                    'recruiting_rank': r.rank,\n",
    "                    'recruiting_points': r.points\n",
    "                })\n",
    "            \n",
    "            print(f\"  {year}: {len(rankings)} teams\")\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_recruiting)\n",
    "        print(f\"\\n✓ Downloaded {len(df)} recruiting rankings\")\n",
    "        return df\n",
    "    \n",
    "    def _download_betting(self, years, season_types):\n",
    "        \"\"\"Download betting lines.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"8. DOWNLOADING BETTING LINES\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_lines = []\n",
    "        \n",
    "        for year in years:\n",
    "            for stype in season_types:\n",
    "                self.track_call(f\"get_lines({year}, {stype})\")\n",
    "                lines = self.betting_api.get_lines(year=year, season_type=stype)\n",
    "                \n",
    "                for game in lines:\n",
    "                    if game.lines:\n",
    "                        # Average across all providers\n",
    "                        spreads = [l.spread for l in game.lines if l.spread is not None]\n",
    "                        totals = [l.over_under for l in game.lines if l.over_under is not None]\n",
    "                        \n",
    "                        all_lines.append({\n",
    "                            'game_id': game.id,\n",
    "                            'betting_spread': np.mean(spreads) if spreads else None,\n",
    "                            'betting_total': np.mean(totals) if totals else None\n",
    "                        })\n",
    "                \n",
    "                print(f\"  {year} {stype}: {len(lines)} games\")\n",
    "                time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_lines)\n",
    "        print(f\"\\n✓ Downloaded betting lines for {len(df)} games\")\n",
    "        return df\n",
    "    \n",
    "    def _download_win_probs(self, years, season_types):\n",
    "        \"\"\"Download pregame win probabilities.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"9. DOWNLOADING PREGAME WIN PROBABILITIES\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_probs = []\n",
    "        \n",
    "        for year in years:\n",
    "            for stype in season_types:\n",
    "                self.track_call(f\"get_pregame_win_probabilities({year}, {stype})\")\n",
    "                \n",
    "                try:\n",
    "                    probs = self.metrics_api.get_pregame_win_probabilities(\n",
    "                        year=year, season_type=stype\n",
    "                    )\n",
    "                    \n",
    "                    for p in probs:\n",
    "                        all_probs.append({\n",
    "                            'game_id': p.game_id,\n",
    "                            'home_win_prob': p.home_win_prob,\n",
    "                            'spread': p.spread\n",
    "                        })\n",
    "                    \n",
    "                    print(f\"  {year} {stype}: {len(probs)} games\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  {year} {stype}: Not available\")\n",
    "                \n",
    "                time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(all_probs)\n",
    "        if len(df) > 0:\n",
    "            print(f\"\\n✓ Downloaded win probabilities for {len(df)} games\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ No win probabilities available\")\n",
    "        return df\n",
    "    \n",
    "    def _merge_all_data(self, games_df, advanced_stats_df, pbp_stats_df, drive_stats_df,\n",
    "                       adjusted_metrics_df, sp_ratings_df, fpi_ratings_df, talent_df, \n",
    "                       recruiting_df, betting_df, win_prob_df):\n",
    "        \"\"\"Merge all datasets into one comprehensive dataset.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"MERGING ALL DATA\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Create base dataset (2 rows per game - home and away)\n",
    "        print(\"\\n1. Creating base dataset...\")\n",
    "        \n",
    "        home_df = games_df.copy()\n",
    "        home_df['team'] = home_df['home_team']\n",
    "        home_df['opponent'] = home_df['away_team']\n",
    "        home_df['team_points'] = home_df['home_points']\n",
    "        home_df['opponent_points'] = home_df['away_points']\n",
    "        home_df['is_home'] = 1\n",
    "        \n",
    "        away_df = games_df.copy()\n",
    "        away_df['team'] = away_df['away_team']\n",
    "        away_df['opponent'] = away_df['home_team']\n",
    "        away_df['team_points'] = away_df['away_points']\n",
    "        away_df['opponent_points'] = away_df['home_points']\n",
    "        away_df['is_home'] = 0\n",
    "        \n",
    "        df = pd.concat([home_df, away_df], ignore_index=True)\n",
    "        \n",
    "        # Add derived columns\n",
    "        df['point_differential'] = df['team_points'] - df['opponent_points']\n",
    "        df['win'] = (df['point_differential'] > 0).astype(int)\n",
    "        df['date'] = pd.to_datetime(df['start_date'])\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek\n",
    "        \n",
    "        print(f\"  Base: {len(df)} team-game records\")\n",
    "        \n",
    "        # Merge advanced stats\n",
    "        print(\"\\n2. Merging advanced stats...\")\n",
    "        if len(advanced_stats_df) > 0:\n",
    "            # Drop opponent column to avoid conflicts\n",
    "            advanced_stats_df = advanced_stats_df.drop(columns=['opponent'], errors='ignore')\n",
    "            df = df.merge(advanced_stats_df, on=['game_id', 'team'], how='left')\n",
    "            print(f\"  ✓ Added {len([c for c in advanced_stats_df.columns if c not in ['game_id', 'team']])} columns\")\n",
    "        \n",
    "        # Merge play-by-play stats\n",
    "        print(\"\\n3. Merging individual game stats...\")\n",
    "        if len(pbp_stats_df) > 0:\n",
    "            # These are game-level stats, merge on game_id and team\n",
    "            pbp_stats_df = pbp_stats_df.drop(columns=['opponent'], errors='ignore')\n",
    "            df = df.merge(pbp_stats_df, on=['game_id', 'team'], how='left')\n",
    "            \n",
    "            stat_cols = [c for c in pbp_stats_df.columns if c.startswith('game_')]\n",
    "            print(f\"  ✓ Added {len(stat_cols)} game stat columns\")\n",
    "        \n",
    "        # Merge drive stats\n",
    "        print(\"\\n4. Merging drive-level stats...\")\n",
    "        if len(drive_stats_df) > 0:\n",
    "            # Print diagnostic info\n",
    "            print(f\"  Drive stats before merge: {len(drive_stats_df)} rows\")\n",
    "            print(f\"  Base data: {len(df)} rows\")\n",
    "            print(f\"  Sample drive teams: {drive_stats_df['team'].head(3).tolist()}\")\n",
    "            print(f\"  Sample base teams: {df['team'].head(3).tolist()}\")\n",
    "            \n",
    "            df = df.merge(drive_stats_df, on=['game_id', 'team'], how='left')\n",
    "            \n",
    "            drive_cols = [c for c in drive_stats_df.columns if c not in ['game_id', 'team']]\n",
    "            \n",
    "            # Check how many merged successfully\n",
    "            merged_count = df[drive_cols[0]].notna().sum() if len(drive_cols) > 0 else 0\n",
    "            print(f\"  ✓ Added {len(drive_cols)} drive stat columns\")\n",
    "            print(f\"  ✓ Matched {merged_count}/{len(df)} rows\")\n",
    "        \n",
    "        # Merge adjusted metrics\n",
    "        print(\"\\n5. Merging adjusted metrics...\")\n",
    "        if len(adjusted_metrics_df) > 0:\n",
    "            # Team adjusted metrics\n",
    "            team_adj = adjusted_metrics_df.drop(columns=['year', 'conference'], errors='ignore').copy()\n",
    "            team_adj.columns = ['team'] + [f'team_{col}' for col in team_adj.columns[1:]]\n",
    "            df = df.merge(team_adj, on='team', how='left')\n",
    "            \n",
    "            # Opponent adjusted metrics\n",
    "            opp_adj = adjusted_metrics_df.drop(columns=['year', 'conference'], errors='ignore').copy()\n",
    "            opp_adj.columns = ['opponent'] + [f'opp_{col}' for col in opp_adj.columns[1:]]\n",
    "            df = df.merge(opp_adj, on='opponent', how='left')\n",
    "            \n",
    "            print(f\"  ✓ Added opponent-adjusted success rates\")\n",
    "        \n",
    "        # Merge SP+ ratings\n",
    "        print(\"\\n6. Merging SP+ ratings...\")\n",
    "        if len(sp_ratings_df) > 0:\n",
    "            # Team SP+\n",
    "            team_sp = sp_ratings_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            team_sp.columns = ['team'] + [f'team_{col}' for col in team_sp.columns[1:]]\n",
    "            df = df.merge(team_sp, on='team', how='left')\n",
    "            \n",
    "            # Opponent SP+\n",
    "            opp_sp = sp_ratings_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            opp_sp.columns = ['opponent'] + [f'opp_{col}' for col in opp_sp.columns[1:]]\n",
    "            df = df.merge(opp_sp, on='opponent', how='left')\n",
    "            \n",
    "            # SP+ differential\n",
    "            if 'team_sp_rating' in df.columns and 'opp_sp_rating' in df.columns:\n",
    "                df['sp_rating_diff'] = df['team_sp_rating'] - df['opp_sp_rating']\n",
    "            \n",
    "            print(f\"  ✓ Added SP+ ratings\")\n",
    "        \n",
    "        # Merge FPI ratings\n",
    "        print(\"\\n7. Merging FPI ratings...\")\n",
    "        if len(fpi_ratings_df) > 0:\n",
    "            team_fpi = fpi_ratings_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            team_fpi.columns = ['team'] + [f'team_{col}' for col in team_fpi.columns[1:]]\n",
    "            df = df.merge(team_fpi, on='team', how='left')\n",
    "            \n",
    "            opp_fpi = fpi_ratings_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            opp_fpi.columns = ['opponent'] + [f'opp_{col}' for col in opp_fpi.columns[1:]]\n",
    "            df = df.merge(opp_fpi, on='opponent', how='left')\n",
    "            \n",
    "            print(f\"  ✓ Added FPI ratings\")\n",
    "        \n",
    "        # Merge talent\n",
    "        print(\"\\n8. Merging talent ratings...\")\n",
    "        if len(talent_df) > 0:\n",
    "            team_talent = talent_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            team_talent.columns = ['team', 'team_talent']\n",
    "            df = df.merge(team_talent, on='team', how='left')\n",
    "            \n",
    "            opp_talent = talent_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            opp_talent.columns = ['opponent', 'opp_talent']\n",
    "            df = df.merge(opp_talent, on='opponent', how='left')\n",
    "            \n",
    "            print(f\"  ✓ Added talent ratings\")\n",
    "        \n",
    "        # Merge recruiting\n",
    "        print(\"\\n9. Merging recruiting rankings...\")\n",
    "        if len(recruiting_df) > 0:\n",
    "            team_rec = recruiting_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            team_rec.columns = ['team'] + [f'team_{col}' for col in team_rec.columns[1:]]\n",
    "            df = df.merge(team_rec, on='team', how='left')\n",
    "            \n",
    "            opp_rec = recruiting_df.drop(columns=['year'], errors='ignore').copy()\n",
    "            opp_rec.columns = ['opponent'] + [f'opp_{col}' for col in opp_rec.columns[1:]]\n",
    "            df = df.merge(opp_rec, on='opponent', how='left')\n",
    "            \n",
    "            if 'team_recruiting_rank' in df.columns and 'opp_recruiting_rank' in df.columns:\n",
    "                df['recruiting_rank_diff'] = df['opp_recruiting_rank'] - df['team_recruiting_rank']\n",
    "            \n",
    "            print(f\"  ✓ Added recruiting rankings\")\n",
    "        \n",
    "        # Merge betting lines\n",
    "        print(\"\\n10. Merging betting lines...\")\n",
    "        if len(betting_df) > 0:\n",
    "            df = df.merge(betting_df, on='game_id', how='left')\n",
    "            \n",
    "            # Adjust spread for away teams\n",
    "            df['team_spread'] = np.where(\n",
    "                df['is_home'] == 1,\n",
    "                df['betting_spread'],\n",
    "                -df['betting_spread']\n",
    "            )\n",
    "            \n",
    "            # Implied win probability from spread\n",
    "            df['implied_win_prob'] = 1 / (1 + np.exp(df['team_spread'] * 0.04))\n",
    "            \n",
    "            print(f\"  ✓ Added betting lines\")\n",
    "        \n",
    "        # Merge win probabilities\n",
    "        print(\"\\n11. Merging win probabilities...\")\n",
    "        if len(win_prob_df) > 0:\n",
    "            df = df.merge(win_prob_df[['game_id', 'home_win_prob']], on='game_id', how='left')\n",
    "            \n",
    "            # Adjust for away teams\n",
    "            df['pregame_win_prob'] = np.where(\n",
    "                df['is_home'] == 1,\n",
    "                df['home_win_prob'],\n",
    "                1 - df['home_win_prob']\n",
    "            )\n",
    "            df = df.drop(columns=['home_win_prob'], errors='ignore')\n",
    "            \n",
    "            print(f\"  ✓ Added win probabilities\")\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_values(['season', 'week', 'date']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\n✓ Merge complete!\")\n",
    "        print(f\"  Final shape: {df.shape}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# USAGE\n",
    "# ============================================================\n",
    "\n",
    "def run_pipeline(api_key, years=[2024], season_type='regular', save_to_csv=True):\n",
    "    \"\"\"\n",
    "    Run the complete pipeline.\n",
    "    \n",
    "    Args:\n",
    "        api_key: Your CFBD API key\n",
    "        years: List of years (e.g., [2024] or list(range(2015, 2025)))\n",
    "        season_type: 'regular', 'postseason', or 'both'\n",
    "        save_to_csv: Whether to save output to CSV\n",
    "    \n",
    "    Returns:\n",
    "        Complete DataFrame\n",
    "    \"\"\"\n",
    "    pipeline = CompleteCFBDataPipeline(api_key)\n",
    "    \n",
    "    df = pipeline.get_all_data(years=years, season_type=season_type)\n",
    "    \n",
    "    # Show summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"FINAL DATASET SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"  Rows (team-games): {len(df)}\")\n",
    "    print(f\"  Columns: {len(df.columns)}\")\n",
    "    print(f\"  Actual games: {len(df) / 2:.0f}\")\n",
    "    print(f\"  Seasons: {sorted(df['season'].unique())}\")\n",
    "    print(f\"  Weeks: {sorted(df['week'].unique())}\")\n",
    "    print(f\"  Teams: {df['team'].nunique()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"Feature breakdown:\")\n",
    "    \n",
    "    # Count feature types\n",
    "    game_info = ['game_id', 'season', 'week', 'date', 'team', 'opponent', 'venue', 'month', 'day_of_week']\n",
    "    outcomes = ['team_points', 'opponent_points', 'point_differential', 'win']\n",
    "    context = ['is_home', 'neutral_site', 'conference_game', 'attendance']\n",
    "    adv_stats = [c for c in df.columns if c.startswith('off_') or c.startswith('def_')]\n",
    "    game_stats = [c for c in df.columns if c.startswith('game_')]\n",
    "    drive_stats = [c for c in df.columns if any(x in c for x in ['drive', 'redzone', 'scoring_zone', 'field_position'])]\n",
    "    adjusted_metrics = [c for c in df.columns if 'adj_' in c]\n",
    "    ratings = [c for c in df.columns if any(x in c for x in ['sp_', 'fpi', 'talent'])]\n",
    "    recruiting = [c for c in df.columns if 'recruiting' in c]\n",
    "    betting = [c for c in df.columns if any(x in c for x in ['spread', 'total', 'prob'])]\n",
    "    \n",
    "    print(f\"  Game info: {len([c for c in game_info if c in df.columns])} columns\")\n",
    "    print(f\"  Outcomes: {len([c for c in outcomes if c in df.columns])} columns\")\n",
    "    print(f\"  Context: {len([c for c in context if c in df.columns])} columns\")\n",
    "    print(f\"  Advanced stats (EPA, success rates): {len(adv_stats)} columns\")\n",
    "    print(f\"  Game stats (passing yards, rushing yards, sacks, etc.): {len(game_stats)} columns\")\n",
    "    print(f\"  Drive stats (field position, drive success): {len(drive_stats)} columns\")\n",
    "    print(f\"  Adjusted metrics (opponent-adjusted): {len(adjusted_metrics)} columns\")\n",
    "    print(f\"  Ratings (SP+, FPI, Talent): {len(ratings)} columns\")\n",
    "    print(f\"  Recruiting: {len(recruiting)} columns\")\n",
    "    print(f\"  Betting lines: {len(betting)} columns\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\n\" + \"Sample data (first 5 rows):\")\n",
    "    print(\"=\" * 70)\n",
    "    sample_cols = ['team', 'opponent', 'week', 'team_points', 'opponent_points', \n",
    "                   'win', 'is_home', 'team_sp_rating', 'opp_sp_rating']\n",
    "    sample_cols = [c for c in sample_cols if c in df.columns]\n",
    "    print(df[sample_cols].head())\n",
    "    \n",
    "    # Show what play-by-play stats are available\n",
    "    if len(game_stats) > 0:\n",
    "        print(\"\\n\" + \"Available individual game statistics:\")\n",
    "        print(\"=\" * 70)\n",
    "        for stat in sorted(game_stats)[:40]:  # Show first 40\n",
    "            print(f\"  • {stat}\")\n",
    "        if len(game_stats) > 40:\n",
    "            print(f\"  ... and {len(game_stats) - 40} more\")\n",
    "    \n",
    "    # Check for missing data\n",
    "    print(\"\\n\" + \"Data completeness:\")\n",
    "    print(\"=\" * 70)\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df) * 100).sort_values(ascending=False)\n",
    "    high_missing = missing_pct[missing_pct > 10].head(10)\n",
    "    \n",
    "    if len(high_missing) > 0:\n",
    "        print(\"  Columns with >10% missing:\")\n",
    "        for col, pct in high_missing.items():\n",
    "            print(f\"    • {col}: {pct:.1f}% missing\")\n",
    "    else:\n",
    "        print(\"  ✓ All major columns have <10% missing data\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    if save_to_csv:\n",
    "        filename = f\"cfb_complete_data_{min(years)}_to_{max(years)}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"\\n✓ Saved to {filename}\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62a52fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key set\n"
     ]
    }
   ],
   "source": [
    "# Replace with your actual API key\n",
    "API_KEY = \"OPHcuzA3Pay3vlBQ+FjanV5j0/XHbJmYCrYF5tPW5yKLFXmpbzs0Ug5BbKwQATJ6\"\n",
    "\n",
    "print(\"✓ API key set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4abc2e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CFB Data Pipeline initialized\n",
      "\n",
      "Testing API connection...\n",
      "✓ API connection successful! Found 134 FBS teams for 2024\n"
     ]
    }
   ],
   "source": [
    "# This will test your API connection\n",
    "pipeline = CompleteCFBDataPipeline(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3efbf7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CFB Data Pipeline initialized\n",
      "\n",
      "Testing API connection...\n",
      "✓ API connection successful! Found 134 FBS teams for 2024\n",
      "\n",
      "======================================================================\n",
      "COMPLETE CFB DATA DOWNLOAD\n",
      "======================================================================\n",
      "\n",
      "Years: [2024]\n",
      "Season type: regular\n",
      "\n",
      "This will download:\n",
      "  ✓ Game results & details\n",
      "  ✓ Advanced game statistics (EPA, explosiveness, etc.)\n",
      "  ✓ Play-by-play aggregated stats (sacks, turnovers, etc.)\n",
      "  ✓ SP+ ratings\n",
      "  ✓ FPI ratings\n",
      "  ✓ Team talent composite\n",
      "  ✓ Recruiting rankings\n",
      "  ✓ Betting lines\n",
      "  ✓ Pregame win probabilities\n",
      "\n",
      "======================================================================\n",
      "1. DOWNLOADING GAME RESULTS\n",
      "======================================================================\n",
      "  API Call #1: get_games(2024, regular)\n",
      "  2024 regular: 3747 games\n",
      "\n",
      "✓ Downloaded 3747 games\n",
      "\n",
      "======================================================================\n",
      "2. DOWNLOADING ADVANCED GAME STATS\n",
      "======================================================================\n",
      "  API Call #2: get_advanced_game_stats(2024, regular)\n",
      "  2024 regular: 3114 team-games\n",
      "\n",
      "✓ Downloaded 3114 advanced stat records\n",
      "\n",
      "======================================================================\n",
      "3. DOWNLOADING GAME-LEVEL TEAM STATS (Passing, Rushing, Sacks, Turnovers)\n",
      "======================================================================\n",
      "  API Call #3: get_game_team_stats(2024, week=1, regular)\n",
      "  2024 regular Week 1: 137 games (274 team-games)\n",
      "  API Call #4: get_game_team_stats(2024, week=2, regular)\n",
      "  2024 regular Week 2: 132 games (264 team-games)\n",
      "  API Call #5: get_game_team_stats(2024, week=3, regular)\n",
      "  2024 regular Week 3: 118 games (236 team-games)\n",
      "  API Call #6: get_game_team_stats(2024, week=4, regular)\n",
      "  2024 regular Week 4: 119 games (238 team-games)\n",
      "  API Call #7: get_game_team_stats(2024, week=5, regular)\n",
      "  2024 regular Week 5: 106 games (212 team-games)\n",
      "  API Call #8: get_game_team_stats(2024, week=6, regular)\n",
      "  2024 regular Week 6: 105 games (210 team-games)\n",
      "  API Call #9: get_game_team_stats(2024, week=7, regular)\n",
      "  2024 regular Week 7: 107 games (214 team-games)\n",
      "  API Call #10: get_game_team_stats(2024, week=8, regular)\n",
      "  2024 regular Week 8: 112 games (224 team-games)\n",
      "  API Call #11: get_game_team_stats(2024, week=9, regular)\n",
      "  2024 regular Week 9: 115 games (230 team-games)\n",
      "  API Call #12: get_game_team_stats(2024, week=10, regular)\n",
      "  2024 regular Week 10: 108 games (216 team-games)\n",
      "  API Call #13: get_game_team_stats(2024, week=11, regular)\n",
      "  2024 regular Week 11: 110 games (220 team-games)\n",
      "  API Call #14: get_game_team_stats(2024, week=12, regular)\n",
      "  2024 regular Week 12: 115 games (230 team-games)\n",
      "  API Call #15: get_game_team_stats(2024, week=13, regular)\n",
      "  2024 regular Week 13: 125 games (250 team-games)\n",
      "  API Call #16: get_game_team_stats(2024, week=14, regular)\n",
      "  2024 regular Week 14: 78 games (156 team-games)\n",
      "  API Call #17: get_game_team_stats(2024, week=15, regular)\n",
      "  2024 regular Week 15: 18 games (36 team-games)\n",
      "  API Call #18: get_game_team_stats(2024, week=16, regular)\n",
      "  2024 regular Week 16: 5 games (10 team-games)\n",
      "\n",
      "✓ Downloaded individual game team stats\n",
      "  Team-games: 3220\n",
      "  Stat categories: 36\n",
      "\n",
      "  Sample stats available:\n",
      "    • game_completionAttempts\n",
      "    • game_defensiveTDs\n",
      "    • game_firstDowns\n",
      "    • game_fourthDownEff\n",
      "    • game_fumblesLost\n",
      "    • game_fumblesRecovered\n",
      "    • game_id\n",
      "    • game_interceptionTDs\n",
      "    • game_interceptionYards\n",
      "    • game_interceptions\n",
      "    • game_kickReturnTDs\n",
      "    • game_kickReturnYards\n",
      "    • game_kickReturns\n",
      "    • game_kickingPoints\n",
      "    • game_netPassingYards\n",
      "    • game_passesDeflected\n",
      "    • game_passesIntercepted\n",
      "    • game_passingTDs\n",
      "    • game_possessionTime\n",
      "    • game_puntReturnTDs\n",
      "    • game_puntReturnYards\n",
      "    • game_puntReturns\n",
      "    • game_qbHurries\n",
      "    • game_rushingAttempts\n",
      "    • game_rushingTDs\n",
      "    ... and 11 more\n",
      "\n",
      "======================================================================\n",
      "4. DOWNLOADING DRIVE-LEVEL DATA (Field Position, Drive Results)\n",
      "======================================================================\n",
      "  API Call #19: get_drives(2024, regular)\n",
      "  2024 regular: 36619 drives\n",
      "\n",
      "Total drives downloaded: 36619\n",
      "Unique games: 1560\n",
      "Unique teams: 299\n",
      "Aggregating drive data by game and team...\n",
      "\n",
      "✓ Aggregated drive data\n",
      "  Team-games: 3120\n",
      "  Games covered: 1560\n",
      "  Teams covered: 299\n",
      "  Metrics: 14\n",
      "\n",
      "  Sample game_ids: [401628319, 401628319, 401628320]\n",
      "  Sample teams: ['Alabama', 'Western Kentucky', 'Arkansas']\n",
      "\n",
      "======================================================================\n",
      "5. DOWNLOADING ADJUSTED METRICS (Opponent-Adjusted Success Rates)\n",
      "======================================================================\n",
      "  API Call #20: get_adjusted_team_season_stats(2024)\n",
      "  2024: Error - 'StatsApi' object has no attribute 'get_advanced_team_season_stats'\n",
      "\n",
      "⚠ No adjusted metrics available\n",
      "\n",
      "======================================================================\n",
      "4. DOWNLOADING SP+ RATINGS\n",
      "======================================================================\n",
      "  API Call #21: get_sp(2024)\n",
      "  2024: 135 teams\n",
      "\n",
      "✓ Downloaded 135 SP+ ratings\n",
      "\n",
      "======================================================================\n",
      "5. DOWNLOADING FPI RATINGS\n",
      "======================================================================\n",
      "  API Call #22: get_fpi(2024)\n",
      "  2024: 134 teams\n",
      "\n",
      "✓ Downloaded 134 FPI ratings\n",
      "\n",
      "======================================================================\n",
      "6. DOWNLOADING TEAM TALENT RATINGS\n",
      "======================================================================\n",
      "  API Call #23: get_talent(2024)\n",
      "  2024: Not available\n",
      "\n",
      "⚠ No talent ratings available\n",
      "\n",
      "======================================================================\n",
      "7. DOWNLOADING RECRUITING RANKINGS\n",
      "======================================================================\n",
      "  API Call #24: get_team_recruiting_rankings(2024)\n",
      "  2024: 194 teams\n",
      "\n",
      "✓ Downloaded 194 recruiting rankings\n",
      "\n",
      "======================================================================\n",
      "8. DOWNLOADING BETTING LINES\n",
      "======================================================================\n",
      "  API Call #25: get_lines(2024, regular)\n",
      "  2024 regular: 1523 games\n",
      "\n",
      "✓ Downloaded betting lines for 1507 games\n",
      "\n",
      "======================================================================\n",
      "9. DOWNLOADING PREGAME WIN PROBABILITIES\n",
      "======================================================================\n",
      "  API Call #26: get_pregame_win_probabilities(2024, regular)\n",
      "  2024 regular: Not available\n",
      "\n",
      "⚠ No win probabilities available\n",
      "\n",
      "======================================================================\n",
      "MERGING ALL DATA\n",
      "======================================================================\n",
      "\n",
      "1. Creating base dataset...\n",
      "  Base: 7494 team-game records\n",
      "\n",
      "2. Merging advanced stats...\n",
      "  ✓ Added 56 columns\n",
      "\n",
      "3. Merging individual game stats...\n",
      "  ✓ Added 36 game stat columns\n",
      "\n",
      "4. Merging drive-level stats...\n",
      "  Drive stats before merge: 3120 rows\n",
      "  Base data: 7494 rows\n",
      "  Sample drive teams: ['Alabama', 'Western Kentucky', 'Arkansas']\n",
      "  Sample base teams: ['Lincoln (CA)', 'Georgia Tech', 'Tarleton State']\n",
      "  ✓ Added 14 drive stat columns\n",
      "  ✓ Matched 3120/7494 rows\n",
      "\n",
      "5. Merging adjusted metrics...\n",
      "\n",
      "6. Merging SP+ ratings...\n",
      "  ✓ Added SP+ ratings\n",
      "\n",
      "7. Merging FPI ratings...\n",
      "  ✓ Added FPI ratings\n",
      "\n",
      "8. Merging talent ratings...\n",
      "\n",
      "9. Merging recruiting rankings...\n",
      "  ✓ Added recruiting rankings\n",
      "\n",
      "10. Merging betting lines...\n",
      "  ✓ Added betting lines\n",
      "\n",
      "11. Merging win probabilities...\n",
      "\n",
      "✓ Merge complete!\n",
      "  Final shape: (7494, 166)\n",
      "\n",
      "======================================================================\n",
      "DOWNLOAD COMPLETE!\n",
      "======================================================================\n",
      "✓ Total API calls used: 26\n",
      "✓ Final dataset shape: (7494, 166)\n",
      "✓ Total games: 3747\n",
      "✓ Total features: 166\n",
      "\n",
      "======================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Dataset shape: (7494, 166)\n",
      "  Rows (team-games): 7494\n",
      "  Columns: 166\n",
      "  Actual games: 3747\n",
      "  Seasons: [np.int64(2024)]\n",
      "  Weeks: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16)]\n",
      "  Teams: 708\n",
      "\n",
      "Feature breakdown:\n",
      "  Game info: 9 columns\n",
      "  Outcomes: 4 columns\n",
      "  Context: 4 columns\n",
      "  Advanced stats (EPA, success rates): 56 columns\n",
      "  Game stats (passing yards, rushing yards, sacks, etc.): 36 columns\n",
      "  Drive stats (field position, drive success): 14 columns\n",
      "  Adjusted metrics (opponent-adjusted): 0 columns\n",
      "  Ratings (SP+, FPI, Talent): 23 columns\n",
      "  Recruiting: 5 columns\n",
      "  Betting lines: 20 columns\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "======================================================================\n",
      "               team          opponent  week  team_points  opponent_points  \\\n",
      "0      Lincoln (CA)  College of Idaho     1          7.0             45.0   \n",
      "1  College of Idaho      Lincoln (CA)     1         45.0              7.0   \n",
      "2      Georgia Tech     Florida State     1         24.0             21.0   \n",
      "3     Florida State      Georgia Tech     1         21.0             24.0   \n",
      "4    Tarleton State           McNeese     1         26.0             23.0   \n",
      "\n",
      "   win  is_home  team_sp_rating  opp_sp_rating  \n",
      "0    0        1             NaN            NaN  \n",
      "1    1        0             NaN            NaN  \n",
      "2    1        1             1.9           -3.2  \n",
      "3    0        0            -3.2            1.9  \n",
      "4    1        1             NaN            NaN  \n",
      "\n",
      "Available individual game statistics:\n",
      "======================================================================\n",
      "  • game_completionAttempts\n",
      "  • game_defensiveTDs\n",
      "  • game_firstDowns\n",
      "  • game_fourthDownEff\n",
      "  • game_fumblesLost\n",
      "  • game_fumblesRecovered\n",
      "  • game_id\n",
      "  • game_interceptionTDs\n",
      "  • game_interceptionYards\n",
      "  • game_interceptions\n",
      "  • game_kickReturnTDs\n",
      "  • game_kickReturnYards\n",
      "  • game_kickReturns\n",
      "  • game_kickingPoints\n",
      "  • game_netPassingYards\n",
      "  • game_passesDeflected\n",
      "  • game_passesIntercepted\n",
      "  • game_passingTDs\n",
      "  • game_possessionTime\n",
      "  • game_puntReturnTDs\n",
      "  • game_puntReturnYards\n",
      "  • game_puntReturns\n",
      "  • game_qbHurries\n",
      "  • game_rushingAttempts\n",
      "  • game_rushingTDs\n",
      "  • game_rushingYards\n",
      "  • game_sacks\n",
      "  • game_tackles\n",
      "  • game_tacklesForLoss\n",
      "  • game_thirdDownEff\n",
      "  • game_totalFumbles\n",
      "  • game_totalPenaltiesYards\n",
      "  • game_totalYards\n",
      "  • game_turnovers\n",
      "  • game_yardsPerPass\n",
      "  • game_yardsPerRushAttempt\n",
      "\n",
      "Data completeness:\n",
      "======================================================================\n",
      "  Columns with >10% missing:\n",
      "    • sp_rating_diff: 79.9% missing\n",
      "    • team_sp_rating: 78.3% missing\n",
      "    • team_fpi_offense: 78.3% missing\n",
      "    • team_sp_ranking: 78.3% missing\n",
      "    • team_sp_offense: 78.3% missing\n",
      "    • team_sp_offense_ranking: 78.3% missing\n",
      "    • team_sp_defense: 78.3% missing\n",
      "    • team_sp_defense_ranking: 78.3% missing\n",
      "    • team_sp_special_teams: 78.3% missing\n",
      "    • opp_sp_rating: 78.3% missing\n",
      "\n",
      "✓ Saved to cfb_complete_data_2024_to_2024.csv\n"
     ]
    }
   ],
   "source": [
    "df = run_pipeline(\n",
    "    api_key=API_KEY,\n",
    "    years=[2024],\n",
    "    season_type='regular',\n",
    "    save_to_csv=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7645cc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     game_id  season  week season_type                 start_date  \\\n",
      "0  401693677    2024     1     regular  2024-08-24 04:00:00+00:00   \n",
      "1  401693677    2024     1     regular  2024-08-24 04:00:00+00:00   \n",
      "2  401635525    2024     1     regular  2024-08-24 16:00:00+00:00   \n",
      "3  401635525    2024     1     regular  2024-08-24 16:00:00+00:00   \n",
      "4  401654665    2024     1     regular  2024-08-24 19:30:00+00:00   \n",
      "\n",
      "   neutral_site  conference_game  attendance  venue_id  \\\n",
      "0          True            False         NaN       NaN   \n",
      "1          True            False         NaN       NaN   \n",
      "2          True             True     47998.0    3504.0   \n",
      "3          True             True     47998.0    3504.0   \n",
      "4         False            False     16125.0    3827.0   \n",
      "\n",
      "                                 venue  home_id       home_team  \\\n",
      "0                                  NaN   124179    Lincoln (CA)   \n",
      "1                                  NaN   124179    Lincoln (CA)   \n",
      "2                        Aviva Stadium       59    Georgia Tech   \n",
      "3                        Aviva Stadium       59    Georgia Tech   \n",
      "4  Memorial Stadium (Stephenville, TX)     2627  Tarleton State   \n",
      "\n",
      "   home_conference  home_points  away_id         away_team away_conference  \\\n",
      "0  Independent DII          7.0   108382  College of Idaho             NaN   \n",
      "1  Independent DII          7.0   108382  College of Idaho             NaN   \n",
      "2              ACC         24.0       52     Florida State             ACC   \n",
      "3              ACC         24.0       52     Florida State             ACC   \n",
      "4              UAC         26.0     2377           McNeese       Southland   \n",
      "\n",
      "   away_points  excitement_index              team          opponent  \\\n",
      "0         45.0               NaN      Lincoln (CA)  College of Idaho   \n",
      "1         45.0               NaN  College of Idaho      Lincoln (CA)   \n",
      "2         21.0          7.822224      Georgia Tech     Florida State   \n",
      "3         21.0          7.822224     Florida State      Georgia Tech   \n",
      "4         23.0          5.564025    Tarleton State           McNeese   \n",
      "\n",
      "   team_points  opponent_points  is_home  point_differential  win  \\\n",
      "0          7.0             45.0        1               -38.0    0   \n",
      "1         45.0              7.0        0                38.0    1   \n",
      "2         24.0             21.0        1                 3.0    1   \n",
      "3         21.0             24.0        0                -3.0    0   \n",
      "4         26.0             23.0        1                 3.0    1   \n",
      "\n",
      "                        date  month  day_of_week  off_plays  off_drives  \\\n",
      "0  2024-08-24 04:00:00+00:00      8            5        NaN         NaN   \n",
      "1  2024-08-24 04:00:00+00:00      8            5        NaN         NaN   \n",
      "2  2024-08-24 16:00:00+00:00      8            5       52.0         7.0   \n",
      "3  2024-08-24 16:00:00+00:00      8            5       58.0         7.0   \n",
      "4  2024-08-24 19:30:00+00:00      8            5       68.0        13.0   \n",
      "\n",
      "    off_ppa  off_total_ppa  off_success_rate  off_explosiveness  \\\n",
      "0       NaN            NaN               NaN                NaN   \n",
      "1       NaN            NaN               NaN                NaN   \n",
      "2  0.390611      20.311767          0.557692           1.118094   \n",
      "3  0.140761       8.164160          0.413793           1.374582   \n",
      "4  0.105721       7.189053          0.426471           0.958774   \n",
      "\n",
      "   off_power_success  off_stuff_rate  off_line_yards  off_line_yards_total  \\\n",
      "0                NaN             NaN             NaN                   NaN   \n",
      "1                NaN             NaN             NaN                   NaN   \n",
      "2           0.833333        0.138889        2.850000                 103.0   \n",
      "3           1.000000        0.233333        2.246667                  67.0   \n",
      "4           1.000000        0.179487        3.212821                 125.0   \n",
      "\n",
      "   off_second_level_yards  off_second_level_yards_total  off_open_field_yards  \\\n",
      "0                     NaN                           NaN                   NaN   \n",
      "1                     NaN                           NaN                   NaN   \n",
      "2                1.361111                          49.0              1.361111   \n",
      "3                0.700000                          21.0              0.600000   \n",
      "4                1.076923                          42.0              1.076923   \n",
      "\n",
      "   off_open_field_yards_total  off_pass_ppa  off_pass_total_ppa  \\\n",
      "0                         NaN           NaN                 NaN   \n",
      "1                         NaN           NaN                 NaN   \n",
      "2                        49.0      0.715004           11.440071   \n",
      "3                        18.0      0.361032           10.108891   \n",
      "4                        42.0      0.031519            0.914052   \n",
      "\n",
      "   off_pass_success_rate  off_pass_explosiveness  off_rush_ppa  \\\n",
      "0                    NaN                     NaN           NaN   \n",
      "1                    NaN                     NaN           NaN   \n",
      "2               0.500000                1.620202      0.246436   \n",
      "3               0.500000                1.659784     -0.064824   \n",
      "4               0.310345                1.426049      0.160897   \n",
      "\n",
      "   off_rush_total_ppa  off_rush_success_rate  off_rush_explosiveness  \\\n",
      "0                 NaN                    NaN                     NaN   \n",
      "1                 NaN                    NaN                     NaN   \n",
      "2            8.871696               0.583333                0.926815   \n",
      "3           -1.944731               0.333333                0.975299   \n",
      "4            6.275001               0.512821                0.748500   \n",
      "\n",
      "   off_standard_downs_ppa  off_standard_downs_success_rate  \\\n",
      "0                     NaN                              NaN   \n",
      "1                     NaN                              NaN   \n",
      "2                0.227712                         0.600000   \n",
      "3               -0.088246                         0.457143   \n",
      "4                0.167068                         0.530612   \n",
      "\n",
      "   off_standard_downs_explosiveness  off_passing_downs_ppa  \\\n",
      "0                               NaN                    NaN   \n",
      "1                               NaN                    NaN   \n",
      "2                          0.889629               0.933607   \n",
      "3                          0.823922               0.489252   \n",
      "4                          0.856441              -0.052489   \n",
      "\n",
      "   off_passing_downs_success_rate  off_passing_downs_explosiveness  def_plays  \\\n",
      "0                             NaN                              NaN        NaN   \n",
      "1                             NaN                              NaN        NaN   \n",
      "2                        0.416667                         2.214727       58.0   \n",
      "3                        0.347826                         2.475902       52.0   \n",
      "4                        0.157895                         1.845661       66.0   \n",
      "\n",
      "   def_drives   def_ppa  def_total_ppa  def_success_rate  def_explosiveness  \\\n",
      "0         NaN       NaN            NaN               NaN                NaN   \n",
      "1         NaN       NaN            NaN               NaN                NaN   \n",
      "2         7.0  0.140761       8.164160          0.413793           1.374582   \n",
      "3         7.0  0.390611      20.311767          0.557692           1.118094   \n",
      "4        13.0  0.141988       9.371226          0.378788           1.584784   \n",
      "\n",
      "   def_power_success  def_stuff_rate  def_line_yards  def_line_yards_total  \\\n",
      "0                NaN             NaN             NaN                   NaN   \n",
      "1                NaN             NaN             NaN                   NaN   \n",
      "2           1.000000        0.233333        2.246667                  67.0   \n",
      "3           0.833333        0.138889        2.850000                 103.0   \n",
      "4           0.666667        0.111111        3.435556                 155.0   \n",
      "\n",
      "   def_second_level_yards  def_second_level_yards_total  def_open_field_yards  \\\n",
      "0                     NaN                           NaN                   NaN   \n",
      "1                     NaN                           NaN                   NaN   \n",
      "2                0.700000                          21.0              0.600000   \n",
      "3                1.361111                          49.0              1.361111   \n",
      "4                1.222222                          55.0              0.977778   \n",
      "\n",
      "   def_open_field_yards_total  def_pass_ppa  def_pass_total_ppa  \\\n",
      "0                         NaN           NaN                 NaN   \n",
      "1                         NaN           NaN                 NaN   \n",
      "2                        18.0      0.361032           10.108891   \n",
      "3                        49.0      0.715004           11.440071   \n",
      "4                        44.0      0.699461           14.688677   \n",
      "\n",
      "   def_pass_success_rate  def_pass_explosiveness  def_rush_ppa  \\\n",
      "0                    NaN                     NaN           NaN   \n",
      "1                    NaN                     NaN           NaN   \n",
      "2               0.500000                1.659784     -0.064824   \n",
      "3               0.500000                1.620202      0.246436   \n",
      "4               0.428571                2.228408     -0.118166   \n",
      "\n",
      "   def_rush_total_ppa  def_rush_success_rate  def_rush_explosiveness  \\\n",
      "0                 NaN                    NaN                     NaN   \n",
      "1                 NaN                    NaN                     NaN   \n",
      "2           -1.944731               0.333333                0.975299   \n",
      "3            8.871696               0.583333                0.926815   \n",
      "4           -5.317450               0.355556                1.222745   \n",
      "\n",
      "   def_standard_downs_ppa  def_standard_downs_success_rate  \\\n",
      "0                     NaN                              NaN   \n",
      "1                     NaN                              NaN   \n",
      "2               -0.088246                         0.457143   \n",
      "3                0.227712                         0.600000   \n",
      "4                0.097076                         0.416667   \n",
      "\n",
      "   def_standard_downs_explosiveness  def_passing_downs_ppa  \\\n",
      "0                               NaN                    NaN   \n",
      "1                               NaN                    NaN   \n",
      "2                          0.823922               0.489252   \n",
      "3                          0.889629               0.933607   \n",
      "4                          1.421230               0.261754   \n",
      "\n",
      "   def_passing_downs_success_rate  def_passing_downs_explosiveness  \\\n",
      "0                             NaN                              NaN   \n",
      "1                             NaN                              NaN   \n",
      "2                        0.347826                         2.475902   \n",
      "3                        0.416667                         2.214727   \n",
      "4                        0.277778                         2.238997   \n",
      "\n",
      "   game_rushingTDs  game_passingTDs  game_kickReturnYards  game_kickReturnTDs  \\\n",
      "0              NaN              NaN                   NaN                 NaN   \n",
      "1              NaN              NaN                   NaN                 NaN   \n",
      "2              3.0              0.0                  20.0                 0.0   \n",
      "3              2.0              0.0                  16.0                 0.0   \n",
      "4              1.0              1.0                  20.0                 0.0   \n",
      "\n",
      "   game_kickReturns  game_kickingPoints  game_interceptionYards  \\\n",
      "0               NaN                 NaN                     NaN   \n",
      "1               NaN                 NaN                     NaN   \n",
      "2               1.0                 6.0                     NaN   \n",
      "3               1.0                 7.0                     NaN   \n",
      "4               1.0                 8.0                     0.0   \n",
      "\n",
      "   game_interceptionTDs  game_passesIntercepted  game_fumblesRecovered  \\\n",
      "0                   NaN                     NaN                    NaN   \n",
      "1                   NaN                     NaN                    NaN   \n",
      "2                   NaN                     NaN                    0.0   \n",
      "3                   NaN                     NaN                    0.0   \n",
      "4                   0.0                     1.0                    3.0   \n",
      "\n",
      "   game_totalFumbles game_possessionTime  game_interceptions  \\\n",
      "0                NaN                 NaN                 NaN   \n",
      "1                NaN                 NaN                 NaN   \n",
      "2                2.0               29:21                 0.0   \n",
      "3                NaN               30:39                 0.0   \n",
      "4                1.0               34:28                 0.0   \n",
      "\n",
      "   game_fumblesLost  game_turnovers game_totalPenaltiesYards  \\\n",
      "0               NaN             NaN                      NaN   \n",
      "1               NaN             NaN                      NaN   \n",
      "2               0.0             0.0                     3-35   \n",
      "3               0.0             0.0                     1-10   \n",
      "4               0.0             0.0                     1-13   \n",
      "\n",
      "   game_yardsPerRushAttempt  game_rushingAttempts  game_rushingYards  \\\n",
      "0                       NaN                   NaN                NaN   \n",
      "1                       NaN                   NaN                NaN   \n",
      "2                       5.3                  36.0              190.0   \n",
      "3                       3.2                  31.0               98.0   \n",
      "4                       4.5                  43.0              195.0   \n",
      "\n",
      "   game_yardsPerPass game_completionAttempts  game_netPassingYards  \\\n",
      "0                NaN                     NaN                   NaN   \n",
      "1                NaN                     NaN                   NaN   \n",
      "2                9.1                   11-16                 146.0   \n",
      "3                7.1                   19-27                 193.0   \n",
      "4                5.5                   12-26                 144.0   \n",
      "\n",
      "   game_totalYards game_fourthDownEff game_thirdDownEff  game_firstDowns  \\\n",
      "0              NaN                NaN               NaN              NaN   \n",
      "1              NaN                NaN               NaN              NaN   \n",
      "2            336.0                0-0               5-9             18.0   \n",
      "3            291.0                2-3              5-12             20.0   \n",
      "4            339.0                1-1              4-14             19.0   \n",
      "\n",
      "   game_puntReturnYards  game_puntReturnTDs  game_puntReturns  \\\n",
      "0                   NaN                 NaN               NaN   \n",
      "1                   NaN                 NaN               NaN   \n",
      "2                   0.0                 0.0               1.0   \n",
      "3                   3.0                 0.0               1.0   \n",
      "4                   1.0                 0.0               2.0   \n",
      "\n",
      "   game_tacklesForLoss  game_defensiveTDs  game_tackles  game_sacks  \\\n",
      "0                  NaN                NaN           NaN         NaN   \n",
      "1                  NaN                NaN           NaN         NaN   \n",
      "2                  7.0                0.0          35.0         1.0   \n",
      "3                  3.0                0.0          35.0         0.0   \n",
      "4                  NaN                NaN           NaN         NaN   \n",
      "\n",
      "   game_qbHurries  game_passesDeflected  avg_start_field_position  \\\n",
      "0             NaN                   NaN                       NaN   \n",
      "1             NaN                   NaN                       NaN   \n",
      "2             1.0                   1.0                 77.428571   \n",
      "3             1.0                   1.0                 73.428571   \n",
      "4             NaN                   NaN                 70.461538   \n",
      "\n",
      "   touchdowns_scored  avg_plays_per_drive  avg_yards_per_drive  total_drives  \\\n",
      "0                NaN                  NaN                  NaN           NaN   \n",
      "1                NaN                  NaN                  NaN           NaN   \n",
      "2                3.0             7.714286            47.285714           7.0   \n",
      "3                2.0             8.571429            44.428571           7.0   \n",
      "4                2.0             5.615385            26.230769          13.0   \n",
      "\n",
      "   drives_to_redzone  drives_to_scoring_zone  drives_to_plus_territory  \\\n",
      "0                NaN                     NaN                       NaN   \n",
      "1                NaN                     NaN                       NaN   \n",
      "2                3.0                     4.0                       4.0   \n",
      "3                2.0                     4.0                       5.0   \n",
      "4                4.0                     6.0                       6.0   \n",
      "\n",
      "   successful_drives  scoring_drive_rate  redzone_rate  scoring_zone_rate  \\\n",
      "0                NaN                 NaN           NaN                NaN   \n",
      "1                NaN                 NaN           NaN                NaN   \n",
      "2                3.0            0.428571      0.428571           0.571429   \n",
      "3                3.0            0.285714      0.285714           0.571429   \n",
      "4                4.0            0.153846      0.307692           0.461538   \n",
      "\n",
      "   plus_territory_rate  drive_success_rate  team_sp_rating  team_sp_ranking  \\\n",
      "0                  NaN                 NaN             NaN              NaN   \n",
      "1                  NaN                 NaN             NaN              NaN   \n",
      "2             0.571429            0.428571             1.9             66.0   \n",
      "3             0.714286            0.428571            -3.2             83.0   \n",
      "4             0.461538            0.307692             NaN              NaN   \n",
      "\n",
      "   team_sp_offense  team_sp_offense_ranking  team_sp_defense  \\\n",
      "0              NaN                      NaN              NaN   \n",
      "1              NaN                      NaN              NaN   \n",
      "2             31.1                     42.0             27.9   \n",
      "3             20.1                    114.0             25.3   \n",
      "4              NaN                      NaN              NaN   \n",
      "\n",
      "   team_sp_defense_ranking  team_sp_special_teams  opp_sp_rating  \\\n",
      "0                      NaN                    NaN            NaN   \n",
      "1                      NaN                    NaN            NaN   \n",
      "2                     79.0                   -1.3           -3.2   \n",
      "3                     58.0                    2.0            1.9   \n",
      "4                      NaN                    NaN            NaN   \n",
      "\n",
      "   opp_sp_ranking  opp_sp_offense  opp_sp_offense_ranking  opp_sp_defense  \\\n",
      "0             NaN             NaN                     NaN             NaN   \n",
      "1             NaN             NaN                     NaN             NaN   \n",
      "2            83.0            20.1                   114.0            25.3   \n",
      "3            66.0            31.1                    42.0            27.9   \n",
      "4             NaN             NaN                     NaN             NaN   \n",
      "\n",
      "   opp_sp_defense_ranking  opp_sp_special_teams  sp_rating_diff  team_fpi  \\\n",
      "0                     NaN                   NaN             NaN       NaN   \n",
      "1                     NaN                   NaN             NaN       NaN   \n",
      "2                    58.0                   2.0             5.1     7.402   \n",
      "3                    79.0                  -1.3            -5.1    -3.911   \n",
      "4                     NaN                   NaN             NaN       NaN   \n",
      "\n",
      "   team_fpi_offense  team_fpi_defense  team_fpi_special_teams  opp_fpi  \\\n",
      "0               NaN               NaN                     NaN      NaN   \n",
      "1               NaN               NaN                     NaN      NaN   \n",
      "2            72.242            58.501                  35.797   -3.911   \n",
      "3            23.689            45.332                  73.417    7.402   \n",
      "4               NaN               NaN                     NaN      NaN   \n",
      "\n",
      "   opp_fpi_offense  opp_fpi_defense  opp_fpi_special_teams  \\\n",
      "0              NaN              NaN                    NaN   \n",
      "1              NaN              NaN                    NaN   \n",
      "2           23.689           45.332                 73.417   \n",
      "3           72.242           58.501                 35.797   \n",
      "4              NaN              NaN                    NaN   \n",
      "\n",
      "   team_recruiting_rank  team_recruiting_points  opp_recruiting_rank  \\\n",
      "0                   NaN                     NaN                  NaN   \n",
      "1                   NaN                     NaN                  NaN   \n",
      "2                  33.0                  214.00                 12.0   \n",
      "3                  12.0                  271.76                 33.0   \n",
      "4                   NaN                     NaN                168.0   \n",
      "\n",
      "   opp_recruiting_points  recruiting_rank_diff  betting_spread  betting_total  \\\n",
      "0                    NaN                   NaN             NaN            NaN   \n",
      "1                    NaN                   NaN             NaN            NaN   \n",
      "2                 271.76                 -21.0       10.666667      54.833333   \n",
      "3                 214.00                  21.0       10.666667      54.833333   \n",
      "4                  27.89                   NaN      -15.500000      63.500000   \n",
      "\n",
      "   team_spread  implied_win_prob  \n",
      "0          NaN               NaN  \n",
      "1          NaN               NaN  \n",
      "2    10.666667          0.394923  \n",
      "3   -10.666667          0.605077  \n",
      "4   -15.500000          0.650219  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ccebfc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lucasjones/Downloads/cfb_power/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a35a833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CFB POWER RANKINGS & WIN PREDICTION FRAMEWORK\n",
      "======================================================================\n",
      "======================================================================\n",
      "FILTERING GAMES\n",
      "======================================================================\n",
      "\n",
      "FBS teams identified: 134\n",
      "\n",
      "Original games: 7494\n",
      "After filter: 1748\n",
      "\n",
      "Game type breakdown:\n",
      "game_type\n",
      "FBS vs FBS    1506\n",
      "FBS vs FCS     242\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "CREATING FCS RANKINGS\n",
      "======================================================================\n",
      "\n",
      "FCS teams: 96\n",
      "\n",
      "Top 10 FCS teams:\n",
      "                  team  fcs_rank  fcs_rating  fcs_games_vs_fbs  \\\n",
      "0        Montana State       1.0     100.520                 1   \n",
      "88            Monmouth       2.0     100.290                 1   \n",
      "51               Idaho       3.0      49.120                 2   \n",
      "47           UT Martin       4.0      43.450                 2   \n",
      "64    St. Francis (PA)       5.0      40.185                 2   \n",
      "18       Southern Utah       6.0      37.750                 2   \n",
      "52   Abilene Christian       7.0      -0.070                 1   \n",
      "15  North Dakota State       8.0      -1.690                 1   \n",
      "69        Gardner-Webb       9.0      -2.390                 2   \n",
      "49    Central Arkansas      10.0      -2.490                 1   \n",
      "\n",
      "    fcs_wins_vs_fbs  \n",
      "0                 1  \n",
      "88                1  \n",
      "51                1  \n",
      "47                1  \n",
      "64                1  \n",
      "18                1  \n",
      "52                0  \n",
      "15                0  \n",
      "69                0  \n",
      "49                0  \n",
      "\n",
      "======================================================================\n",
      "PHASE 1: ANALYZING WIN PREDICTORS\n",
      "======================================================================\n",
      "\n",
      "Analyzing 1498 FBS vs FBS games\n",
      "Available predictors: 25\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert [['5-9' '5-12' '8-18' ... '7-13' '5-14' '7-13']] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 520\u001b[39m\n\u001b[32m    517\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mcfb_complete_data_2024_to_2024.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m df_final, win_analysis, preseason_rankings, fcs_rankings = \u001b[43mrun_complete_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[32m    523\u001b[39m df_final.to_csv(\u001b[33m'\u001b[39m\u001b[33mcfb_data_with_rankings.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 489\u001b[39m, in \u001b[36mrun_complete_analysis\u001b[39m\u001b[34m(df_raw)\u001b[39m\n\u001b[32m    482\u001b[39m df_filtered = df_filtered.merge(\n\u001b[32m    483\u001b[39m     fcs_rankings[[\u001b[33m'\u001b[39m\u001b[33mteam\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfcs_rating\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfcs_rank\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m    484\u001b[39m     on=\u001b[33m'\u001b[39m\u001b[33mteam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    485\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    486\u001b[39m )\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# Phase 1: Identify important variables\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m win_analysis = \u001b[43manalyze_win_predictors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# Phase 2: Preseason rankings (for 2024)\u001b[39;00m\n\u001b[32m    492\u001b[39m preseason_2024 = create_preseason_rankings(df_filtered, year=\u001b[32m2024\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 181\u001b[39m, in \u001b[36manalyze_win_predictors\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable predictors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(available_predictors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m X = df_analysis[available_predictors].fillna(\u001b[43mdf_analysis\u001b[49m\u001b[43m[\u001b[49m\u001b[43mavailable_predictors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    182\u001b[39m y = df_analysis[\u001b[33m'\u001b[39m\u001b[33mwin\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Method 1: Random Forest Feature Importance\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/frame.py:11733\u001b[39m, in \u001b[36mDataFrame.median\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  11725\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n\u001b[32m  11726\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmedian\u001b[39m(\n\u001b[32m  11727\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11731\u001b[39m     **kwargs,\n\u001b[32m  11732\u001b[39m ):\n\u001b[32m> \u001b[39m\u001b[32m11733\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11734\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[32m  11735\u001b[39m         result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/generic.py:12496\u001b[39m, in \u001b[36mNDFrame.median\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmedian\u001b[39m(\n\u001b[32m  12490\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12491\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12494\u001b[39m     **kwargs,\n\u001b[32m  12495\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12497\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedian\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmedian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/generic.py:12442\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12438\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12440\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/frame.py:11589\u001b[39m, in \u001b[36mDataFrame._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m  11585\u001b[39m     df = df.T\n\u001b[32m  11587\u001b[39m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[32m  11588\u001b[39m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m11589\u001b[39m res = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11590\u001b[39m out = df._constructor_from_mgr(res, axes=res.axes).iloc[\u001b[32m0\u001b[39m]\n\u001b[32m  11591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out.dtype != \u001b[33m\"\u001b[39m\u001b[33mboolean\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:1519\u001b[39m, in \u001b[36mBlockManager.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m   1517\u001b[39m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] = []\n\u001b[32m   1518\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m-> \u001b[39m\u001b[32m1519\u001b[39m     nbs = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1520\u001b[39m     res_blocks.extend(nbs)\n\u001b[32m   1522\u001b[39m index = Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/internals/blocks.py:406\u001b[39m, in \u001b[36mBlock.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.values.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    409\u001b[39m         res_values = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/frame.py:11508\u001b[39m, in \u001b[36mDataFrame._reduce.<locals>.blk_func\u001b[39m\u001b[34m(values, axis)\u001b[39m\n\u001b[32m  11506\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.array([result])\n\u001b[32m  11507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m11508\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/cfb_power/.venv/lib/python3.13/site-packages/pandas/core/nanops.py:787\u001b[39m, in \u001b[36mnanmedian\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    785\u001b[39m     inferred = lib.infer_dtype(values)\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    789\u001b[39m     values = values.astype(\u001b[33m\"\u001b[39m\u001b[33mf8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Cannot convert [['5-9' '5-12' '8-18' ... '7-13' '5-14' '7-13']] to numeric"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CFB Power Rankings & Win Prediction Framework\n",
    "\n",
    "Phase 1: Identify Most Important Variables\n",
    "Phase 2: Create Preseason Rankings  \n",
    "Phase 3: Build Season-Cumulative Features\n",
    "Phase 4: Quantify SOS and Team Rankings\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 0: DATA PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "def filter_games(df):\n",
    "    \"\"\"\n",
    "    Filter to keep FBS vs FBS and FBS vs FCS games.\n",
    "    Drop FCS vs FCS, and games vs lower divisions.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"FILTERING GAMES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Identify FBS teams (those with SP+ ratings)\n",
    "    fbs_teams = df[df['team_sp_rating'].notna()]['team'].unique()\n",
    "    \n",
    "    print(f\"\\nFBS teams identified: {len(fbs_teams)}\")\n",
    "    \n",
    "    # Keep games where at least one team is FBS\n",
    "    df_filtered = df[\n",
    "        (df['team'].isin(fbs_teams)) | \n",
    "        (df['opponent'].isin(fbs_teams))\n",
    "    ].copy()\n",
    "    \n",
    "    # Classify game types\n",
    "    df_filtered['game_type'] = 'Unknown'\n",
    "    df_filtered.loc[\n",
    "        (df_filtered['team'].isin(fbs_teams)) & \n",
    "        (df_filtered['opponent'].isin(fbs_teams)), \n",
    "        'game_type'\n",
    "    ] = 'FBS vs FBS'\n",
    "    \n",
    "    df_filtered.loc[\n",
    "        ((df_filtered['team'].isin(fbs_teams)) & (~df_filtered['opponent'].isin(fbs_teams))) |\n",
    "        ((~df_filtered['team'].isin(fbs_teams)) & (df_filtered['opponent'].isin(fbs_teams))),\n",
    "        'game_type'\n",
    "    ] = 'FBS vs FCS'\n",
    "    \n",
    "    print(f\"\\nOriginal games: {len(df)}\")\n",
    "    print(f\"After filter: {len(df_filtered)}\")\n",
    "    print(f\"\\nGame type breakdown:\")\n",
    "    print(df_filtered['game_type'].value_counts())\n",
    "    \n",
    "    return df_filtered, fbs_teams\n",
    "\n",
    "\n",
    "def create_fcs_rankings(df, fbs_teams):\n",
    "    \"\"\"\n",
    "    Create simple power rankings for FCS teams based on performance vs FBS.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CREATING FCS RANKINGS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get FCS teams\n",
    "    fcs_teams = df[~df['team'].isin(fbs_teams)]['team'].unique()\n",
    "    \n",
    "    print(f\"\\nFCS teams: {len(fcs_teams)}\")\n",
    "    \n",
    "    fcs_rankings = []\n",
    "    \n",
    "    for team in fcs_teams:\n",
    "        # Get games where FCS team played FBS opponent\n",
    "        team_games = df[\n",
    "            (df['team'] == team) & \n",
    "            (df['opponent'].isin(fbs_teams))\n",
    "        ]\n",
    "        \n",
    "        if len(team_games) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate metrics\n",
    "        games_played = len(team_games)\n",
    "        wins = team_games['win'].sum()\n",
    "        win_pct = wins / games_played if games_played > 0 else 0\n",
    "        avg_point_diff = team_games['point_differential'].mean()\n",
    "        avg_opp_sp_rating = team_games['opp_sp_rating'].mean()\n",
    "        \n",
    "        # Simple FCS rating formula\n",
    "        # Base on performance vs FBS, adjusted for opponent quality\n",
    "        fcs_rating = (\n",
    "            (win_pct * 100) +  # Win % weight\n",
    "            (avg_point_diff / 2) +  # Point differential\n",
    "            (avg_opp_sp_rating * 0.1)  # Opponent strength\n",
    "        )\n",
    "        \n",
    "        fcs_rankings.append({\n",
    "            'team': team,\n",
    "            'fcs_rating': fcs_rating,\n",
    "            'fcs_games_vs_fbs': games_played,\n",
    "            'fcs_wins_vs_fbs': wins,\n",
    "            'fcs_win_pct_vs_fbs': win_pct,\n",
    "            'fcs_avg_point_diff': avg_point_diff\n",
    "        })\n",
    "    \n",
    "    fcs_df = pd.DataFrame(fcs_rankings)\n",
    "    fcs_df['fcs_rank'] = fcs_df['fcs_rating'].rank(ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 10 FCS teams:\")\n",
    "    print(fcs_df.nsmallest(10, 'fcs_rank')[\n",
    "        ['team', 'fcs_rank', 'fcs_rating', 'fcs_games_vs_fbs', 'fcs_wins_vs_fbs']\n",
    "    ])\n",
    "    \n",
    "    return fcs_df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 1: IDENTIFY MOST IMPORTANT VARIABLES FOR WINNING\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_win_predictors(df):\n",
    "    \"\"\"\n",
    "    Use multiple methods to identify which stats are most predictive of wins.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PHASE 1: ANALYZING WIN PREDICTORS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Filter to complete cases (FBS vs FBS with all stats)\n",
    "    df_analysis = df[\n",
    "        (df['game_type'] == 'FBS vs FBS') &\n",
    "        (df['team_points'].notna()) &\n",
    "        (df['off_ppa'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"\\nAnalyzing {len(df_analysis)} FBS vs FBS games\")\n",
    "    \n",
    "    # Define potential predictor variables\n",
    "    predictor_categories = {\n",
    "        'efficiency': [\n",
    "            'off_ppa', 'def_ppa', 'off_success_rate', 'def_success_rate',\n",
    "            'off_explosiveness', 'def_explosiveness'\n",
    "        ],\n",
    "        'traditional_stats': [\n",
    "            'game_totalYards', 'game_netPassingYards', 'game_rushingYards',\n",
    "            'game_turnovers', 'game_sacks', 'game_thirdDownEff'\n",
    "        ],\n",
    "        'situational': [\n",
    "            'off_standard_downs_success_rate', 'off_passing_downs_success_rate',\n",
    "            'off_stuff_rate', 'off_power_success'\n",
    "        ],\n",
    "        'field_position': [\n",
    "            'avg_start_field_position', 'redzone_rate', 'scoring_zone_rate',\n",
    "            'drive_success_rate'\n",
    "        ],\n",
    "        'ratings': [\n",
    "            'team_sp_rating', 'team_sp_offense', 'team_sp_defense',\n",
    "            'team_fpi', 'team_recruiting_rank'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Flatten all predictors\n",
    "    all_predictors = []\n",
    "    for category in predictor_categories.values():\n",
    "        all_predictors.extend(category)\n",
    "    \n",
    "    # Filter to available columns\n",
    "    available_predictors = [col for col in all_predictors if col in df_analysis.columns]\n",
    "    \n",
    "    print(f\"Available predictors: {len(available_predictors)}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df_analysis[available_predictors].fillna(df_analysis[available_predictors].median())\n",
    "    y = df_analysis['win']\n",
    "    \n",
    "    # Method 1: Random Forest Feature Importance\n",
    "    print(\"\\n1. Random Forest Feature Importance:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': available_predictors,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 15 Most Important Features (Random Forest):\")\n",
    "    for idx, row in feature_importance.head(15).iterrows():\n",
    "        print(f\"  {row['feature']:40s} {row['importance']:.4f}\")\n",
    "    \n",
    "    # Method 2: Correlation with winning\n",
    "    print(\"\\n\\n2. Correlation with Winning:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    correlations = pd.DataFrame({\n",
    "        'feature': available_predictors,\n",
    "        'correlation': [X[col].corr(y) for col in available_predictors]\n",
    "    }).sort_values('correlation', ascending=False, key=abs)\n",
    "    \n",
    "    print(\"\\nTop 15 Features by Correlation:\")\n",
    "    for idx, row in correlations.head(15).iterrows():\n",
    "        print(f\"  {row['feature']:40s} {row['correlation']:+.4f}\")\n",
    "    \n",
    "    # Method 3: Model Performance by Category\n",
    "    print(\"\\n\\n3. Model Performance by Feature Category:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    category_performance = {}\n",
    "    \n",
    "    for category_name, features in predictor_categories.items():\n",
    "        available_features = [f for f in features if f in available_predictors]\n",
    "        \n",
    "        if len(available_features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_cat = X[available_features]\n",
    "        \n",
    "        lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr.fit(X_cat, y)\n",
    "        \n",
    "        y_pred = lr.predict(X_cat)\n",
    "        y_pred_proba = lr.predict_proba(X_cat)[:, 1]\n",
    "        \n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        auc = roc_auc_score(y, y_pred_proba)\n",
    "        \n",
    "        category_performance[category_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'n_features': len(available_features)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n  {category_name:20s} Accuracy: {accuracy:.3f}  AUC: {auc:.3f}  ({len(available_features)} features)\")\n",
    "    \n",
    "    # Summary recommendations\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RECOMMENDATIONS FOR WIN PREDICTION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    top_features = feature_importance.head(10)['feature'].tolist()\n",
    "    \n",
    "    print(\"\\n✓ Top 10 Features for Win Prediction:\")\n",
    "    for i, feat in enumerate(top_features, 1):\n",
    "        print(f\"  {i:2d}. {feat}\")\n",
    "    \n",
    "    return {\n",
    "        'feature_importance': feature_importance,\n",
    "        'correlations': correlations,\n",
    "        'category_performance': category_performance,\n",
    "        'top_features': top_features\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 2: CREATE PRESEASON RANKINGS\n",
    "# ============================================================================\n",
    "\n",
    "def create_preseason_rankings(df, year=2024):\n",
    "    \"\"\"\n",
    "    Create preseason rankings using:\n",
    "    - Previous season performance\n",
    "    - Recruiting rankings\n",
    "    - Returning production (when available)\n",
    "    - SP+ ratings\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"PHASE 2: CREATING PRESEASON RANKINGS FOR {year}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get previous season final rankings\n",
    "    prev_year = year - 1\n",
    "    prev_season = df[df['season'] == prev_year].copy()\n",
    "    \n",
    "    # Calculate end-of-season metrics for each team\n",
    "    team_metrics = prev_season.groupby('team').agg({\n",
    "        'win': 'sum',\n",
    "        'game_id': 'count',\n",
    "        'point_differential': 'sum',\n",
    "        'off_ppa': 'mean',\n",
    "        'def_ppa': 'mean',\n",
    "        'team_sp_rating': 'last',\n",
    "        'team_recruiting_rank': 'last'\n",
    "    }).reset_index()\n",
    "    \n",
    "    team_metrics.columns = [\n",
    "        'team', 'prev_wins', 'prev_games', 'prev_point_diff',\n",
    "        'prev_off_ppa', 'prev_def_ppa', 'prev_sp_rating', 'recruiting_rank'\n",
    "    ]\n",
    "    \n",
    "    # Calculate win percentage\n",
    "    team_metrics['prev_win_pct'] = team_metrics['prev_wins'] / team_metrics['prev_games']\n",
    "    \n",
    "    # Create composite preseason rating\n",
    "    # Normalize each component\n",
    "    team_metrics['win_score'] = (team_metrics['prev_win_pct'] - 0.5) * 100\n",
    "    team_metrics['sp_score'] = team_metrics['prev_sp_rating'].fillna(0)\n",
    "    team_metrics['recruiting_score'] = -(team_metrics['recruiting_rank'].fillna(100) - 50)\n",
    "    \n",
    "    # Weighted preseason score\n",
    "    team_metrics['preseason_rating'] = (\n",
    "        team_metrics['win_score'] * 0.3 +\n",
    "        team_metrics['sp_score'] * 0.4 +\n",
    "        team_metrics['recruiting_score'] * 0.3\n",
    "    )\n",
    "    \n",
    "    # Rank teams\n",
    "    team_metrics['preseason_rank'] = team_metrics['preseason_rating'].rank(ascending=False)\n",
    "    \n",
    "    team_metrics = team_metrics.sort_values('preseason_rank')\n",
    "    \n",
    "    print(f\"\\nTop 25 Preseason Rankings for {year}:\")\n",
    "    print(team_metrics.head(25)[\n",
    "        ['team', 'preseason_rank', 'preseason_rating', 'prev_wins', 'prev_sp_rating', 'recruiting_rank']\n",
    "    ].to_string(index=False))\n",
    "    \n",
    "    return team_metrics[['team', 'preseason_rank', 'preseason_rating']]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 3: BUILD SEASON-CUMULATIVE FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "def create_cumulative_features(df):\n",
    "    \"\"\"\n",
    "    For each game, calculate season-to-date stats up to (but not including) that game.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PHASE 3: CREATING SEASON-CUMULATIVE FEATURES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Sort by team, season, and date\n",
    "    df = df.sort_values(['team', 'season', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # Stats to track cumulatively\n",
    "    cumulative_stats = [\n",
    "        'team_points', 'opponent_points', 'point_differential', 'win',\n",
    "        'off_ppa', 'def_ppa', 'off_success_rate', 'def_success_rate',\n",
    "        'off_explosiveness', 'def_explosiveness',\n",
    "        'game_totalYards', 'game_turnovers', 'game_sacks'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available stats\n",
    "    available_stats = [s for s in cumulative_stats if s in df.columns]\n",
    "    \n",
    "    print(f\"\\nTracking {len(available_stats)} cumulative statistics\")\n",
    "    \n",
    "    # Create cumulative features\n",
    "    for stat in available_stats:\n",
    "        # Expanding mean (excludes current game)\n",
    "        df[f'{stat}_season_avg'] = (\n",
    "            df.groupby(['team', 'season'])[stat]\n",
    "            .transform(lambda x: x.shift(1).expanding().mean())\n",
    "        )\n",
    "        \n",
    "        # Last 3 games average\n",
    "        df[f'{stat}_L3'] = (\n",
    "            df.groupby(['team', 'season'])[stat]\n",
    "            .transform(lambda x: x.shift(1).rolling(window=3, min_periods=1).mean())\n",
    "        )\n",
    "    \n",
    "    # Games played so far\n",
    "    df['games_played'] = df.groupby(['team', 'season']).cumcount()\n",
    "    \n",
    "    # Current record\n",
    "    df['season_wins'] = (\n",
    "        df.groupby(['team', 'season'])['win']\n",
    "        .transform(lambda x: x.shift(1).cumsum())\n",
    "    )\n",
    "    \n",
    "    df['season_win_pct'] = df['season_wins'] / df['games_played'].replace(0, 1)\n",
    "    \n",
    "    print(f\"\\n✓ Created cumulative features\")\n",
    "    print(f\"  Season averages: {len([c for c in df.columns if '_season_avg' in c])}\")\n",
    "    print(f\"  Last 3 game averages: {len([c for c in df.columns if '_L3' in c])}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 4: QUANTIFY STRENGTH OF SCHEDULE & RANKINGS\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_sos_and_rankings(df):\n",
    "    \"\"\"\n",
    "    Calculate strength of schedule and create power rankings throughout the season.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PHASE 4: CALCULATING SOS & POWER RANKINGS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Sort by season and date\n",
    "    df = df.sort_values(['season', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # For each game, calculate opponent's current rating\n",
    "    print(\"\\n1. Calculating Strength of Schedule...\")\n",
    "    \n",
    "    # Average opponent SP+ rating faced (season-to-date)\n",
    "    df['sos_sp_rating'] = (\n",
    "        df.groupby(['team', 'season'])['opp_sp_rating']\n",
    "        .transform(lambda x: x.expanding().mean())\n",
    "    )\n",
    "    \n",
    "    # For SOS based on opponent win %, we need to calculate it differently\n",
    "    # Since we can't easily map opponent names to their current records\n",
    "    # We'll use a simpler approach: average of opponent's SP+ ratings\n",
    "    \n",
    "    # Create power rankings\n",
    "    print(\"\\n2. Creating Weekly Power Rankings...\")\n",
    "    \n",
    "    # Calculate composite power rating for each team-week\n",
    "    df['power_rating'] = 0.0\n",
    "    \n",
    "    # Ensure numeric columns\n",
    "    df['season_win_pct'] = pd.to_numeric(df['season_win_pct'], errors='coerce')\n",
    "    df['point_differential_season_avg'] = pd.to_numeric(df['point_differential_season_avg'], errors='coerce')\n",
    "    df['team_sp_rating'] = pd.to_numeric(df['team_sp_rating'], errors='coerce')\n",
    "    df['sos_sp_rating'] = pd.to_numeric(df['sos_sp_rating'], errors='coerce')\n",
    "    \n",
    "    # Components of power rating:\n",
    "    # 1. Season win percentage (30%)\n",
    "    df['power_rating'] += df['season_win_pct'].fillna(0.5) * 30\n",
    "    \n",
    "    # 2. Point differential per game (20%)\n",
    "    df['power_rating'] += (df['point_differential_season_avg'].fillna(0) / 10) * 20\n",
    "    \n",
    "    # 3. SP+ rating (30%)\n",
    "    df['power_rating'] += (df['team_sp_rating'].fillna(0) / 2) * 30\n",
    "    \n",
    "    # 4. Strength of schedule adjusted (20%)\n",
    "    df['power_rating'] += (df['sos_sp_rating'].fillna(0) / 5) * 20\n",
    "    \n",
    "    # Rank teams within each week\n",
    "    df['current_rank'] = df.groupby(['season', 'week'])['power_rating'].rank(ascending=False, method='min')\n",
    "    \n",
    "    # End of season rankings (after last game)\n",
    "    end_of_season = df.groupby(['team', 'season']).last().reset_index()\n",
    "    end_of_season['final_rank'] = end_of_season.groupby('season')['power_rating'].rank(ascending=False)\n",
    "    \n",
    "    # Merge final rank back\n",
    "    df = df.merge(\n",
    "        end_of_season[['team', 'season', 'final_rank']],\n",
    "        on=['team', 'season'],\n",
    "        how='left',\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "    \n",
    "    # Drop duplicate columns if any\n",
    "    df = df[[c for c in df.columns if not c.endswith('_dup')]]\n",
    "    \n",
    "    print(f\"\\n✓ Strength of Schedule calculated\")\n",
    "    print(f\"✓ Power rankings created (current_rank and final_rank)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def run_complete_analysis(df_raw):\n",
    "    \"\"\"\n",
    "    Run complete analysis pipeline.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CFB POWER RANKINGS & WIN PREDICTION FRAMEWORK\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Phase 0: Filter data\n",
    "    df_filtered, fbs_teams = filter_games(df_raw)\n",
    "    fcs_rankings = create_fcs_rankings(df_filtered, fbs_teams)\n",
    "    \n",
    "    # Merge FCS rankings back to main dataset\n",
    "    df_filtered = df_filtered.merge(\n",
    "        fcs_rankings[['team', 'fcs_rating', 'fcs_rank']],\n",
    "        on='team',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Phase 1: Identify important variables\n",
    "    win_analysis = analyze_win_predictors(df_filtered)\n",
    "    \n",
    "    # Phase 2: Preseason rankings (for 2024)\n",
    "    preseason_2024 = create_preseason_rankings(df_filtered, year=2024)\n",
    "    \n",
    "    # Phase 3: Cumulative features\n",
    "    df_with_cumulative = create_cumulative_features(df_filtered)\n",
    "    \n",
    "    # Phase 4: SOS and rankings\n",
    "    df_final = calculate_sos_and_rankings(df_with_cumulative)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nFinal dataset: {df_final.shape}\")\n",
    "    print(f\"  Original: {df_raw.shape[0]} rows, {df_raw.shape[1]} columns\")\n",
    "    print(f\"  Final: {df_final.shape[0]} rows, {df_final.shape[1]} columns\")\n",
    "    print(f\"  Added: {df_final.shape[1] - df_raw.shape[1]} new feature columns\")\n",
    "    \n",
    "    return df_final, win_analysis, preseason_2024, fcs_rankings\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    df = pd.read_csv('cfb_complete_data_2024_to_2024.csv')\n",
    "    \n",
    "    # Run analysis\n",
    "    df_final, win_analysis, preseason_rankings, fcs_rankings = run_complete_analysis(df)\n",
    "    \n",
    "    # Save results\n",
    "    df_final.to_csv('cfb_data_with_rankings.csv', index=False)\n",
    "    win_analysis['feature_importance'].to_csv('feature_importance.csv', index=False)\n",
    "    preseason_rankings.to_csv('preseason_rankings_2024.csv', index=False)\n",
    "    fcs_rankings.to_csv('fcs_rankings.csv', index=False)\n",
    "    \n",
    "    print(\"\\n✓ All results saved!\")\n",
    "    print(\"  - cfb_data_with_rankings.csv\")\n",
    "    print(\"  - feature_importance.csv\")\n",
    "    print(\"  - preseason_rankings_2024.csv\")\n",
    "    print(\"  - fcs_rankings.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
